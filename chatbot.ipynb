{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a279842d",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b8ac435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from google.generativeai import GenerativeModel, embed_content\n",
    "# Konfigurera API-nyckeln direkt. Detta är det nya standardiserade sättet.\n",
    "import google.generativeai as genai # Behåll denna för att kunna kalla genai.generate_content etc.\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))\n",
    "\n",
    "\n",
    "\n",
    "# from google import genai\n",
    "# client = genai.Client(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c62642b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallå där! Du pratar med en stor språkmodell, en sorts AI. \n",
      "\n",
      "Här är ett skämt om Terraforming Mars:\n",
      "\n",
      "Varför tar det så lång tid att spela Terraforming Mars?\n",
      "\n",
      "För att alla är så upptagna med att terraformera Mars att ingen hinner terraformera bordet och städa upp efter sig!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "response = model.generate_content(   \n",
    "    contents=\"Hej där, vem pratar jag med? Kan du säga ett skämt om personer som spelar terraforming mars?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488dc02",
   "metadata": {},
   "source": [
    "### Extracting Text from a PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff6803e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Läser in PDF: AMAZONIS_and_VASTITAS_ENG.pdf\n",
      "Läser in PDF: Automa-rulebook-A-08-15-2023.pdf\n",
      "Läser in PDF: Automa-rulebook-B-08-15-2023.pdf\n",
      "Läser in PDF: Automa-rulebook-C-11-14-2023.pdf\n",
      "Läser in PDF: COLONIES_ENG.pdf\n",
      "Skippar fil: evaluation_questions.json (varken PDF eller TXT)\n",
      "Läser in PDF: HELLAS_and_ELYSIUM_ENG.pdf\n",
      "Läser in PDF: PRELUDE2_RULES_ENG.pdf\n",
      "Läser in PDF: PRELUDE_ENG_RULES.pdf\n",
      "Läser in TXT (projektkort): Terraforming_Mars_Project_Cards.txt\n",
      "Läser in PDF: Terraforming_mars_rulebook_english.pdf\n",
      "Läser in PDF: Terraforming_mars_rulebook_swedish.pdf\n",
      "Läser in PDF: TURMOIL_ENG.pdf\n",
      "Läser in PDF: UTOPIA_and_ CIMERIA_ENG.pdf\n",
      "Läser in PDF: VENUS_ENG.pdf\n",
      "\n",
      "Totalt antal regelböcker (PDFs) inlästa: 12\n",
      "Exempel (första 200 tecken från första regelboken 'AMAZONIS_and_VASTITAS_ENG.pdf'):\n",
      "EXTRA MATERIAL INCLUDED!\n",
      "Explore the ancient sea of Vastitas Borealis, or play the larger Amazonis map \n",
      "with longer global parameters! Each map depicts a new region of Mars, with new \n",
      "placement bonuse\n",
      "\n",
      "Totalt antal projektkortsfiler (TXTs) inlästa: 1\n",
      "Exempel (första 200 tecken från första projektkortsfilen 'Terraforming_Mars_Project_Cards.txt'):\n",
      "﻿001gcolor>: Colonizer Training Camp\n",
      "Jovian tag, Building tag\n",
      "Cost: 8\n",
      "Requires: max 5% O2\n",
      "------\n",
      "(Oxygen must be 5% or less.)\n",
      "VP: 2\n",
      "\n",
      "002gcolor>:* Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Require\n",
      "\n",
      "Storlek på kombinerad regelbokstext: 170217 tecken\n",
      "Storlek på kombinerad projektkortstext: 64986 tecken\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file and prints the first `num_chars` characters.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # Get the page\n",
    "        text = page.get_text(\"text\")  # Extract text from the page\n",
    "        all_text += text  # Append the extracted text to the all_text string\n",
    "\n",
    "    return all_text  # Return the extracted text\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        project_cards = f.read()\n",
    "    return project_cards\n",
    "\n",
    "\n",
    "# Definiera din datamapp\n",
    "data_folder_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\" #\n",
    "\n",
    "# Lista för att lagra all text från regelböcker (PDFs)\n",
    "all_rule_books_content = []\n",
    "\n",
    "# Lista för att lagra all text från projektkort (TXTs)\n",
    "all_project_cards_content = []\n",
    "\n",
    "# Iterera över alla filer i data-mappen\n",
    "for filename in os.listdir(data_folder_path): #\n",
    "    file_path = os.path.join(data_folder_path, filename) #\n",
    "\n",
    "    if filename.lower().endswith(\".pdf\"): #\n",
    "\n",
    "        print(f\"Läser in PDF: {filename}\")\n",
    "        extracted_text = extract_text_from_pdf(file_path)\n",
    "        if extracted_text: # Lägg bara till om text extraherades framgångsrikt\n",
    "            all_rule_books_content.append({\"filename\": filename, \"content\": extracted_text}) #\n",
    "\n",
    "    elif filename.lower().endswith(\".txt\"): # Identifiera om det är projektkort eller andra txt-filer. Kan också lägga till fler txt-filer med fler kort i framtiden.\n",
    "        if \"project_cards\" in filename.lower(): #\n",
    "            print(f\"Läser in TXT (projektkort): {filename}\")\n",
    "            extracted_text = read_txt_file(file_path)\n",
    "            if extracted_text: # Lägg bara till om text extraherades framgångsrikt\n",
    "                all_project_cards_content.append({\"filename\": filename, \"content\": extracted_text}) #\n",
    "        else:\n",
    "            print(f\"Skippar TXT: {filename} (inte identifierad som projektkort)\")\n",
    "    else:\n",
    "        print(f\"Skippar fil: {filename} (varken PDF eller TXT)\")\n",
    "\n",
    "# Skriv ut en sammanfattning\n",
    "print(f\"\\nTotalt antal regelböcker (PDFs) inlästa: {len(all_rule_books_content)}\")\n",
    "if all_rule_books_content:\n",
    "    print(f\"Exempel (första 200 tecken från första regelboken '{all_rule_books_content[0]['filename']}'):\\n{all_rule_books_content[0]['content'][:200]}\\n\")\n",
    "\n",
    "print(f\"Totalt antal projektkortsfiler (TXTs) inlästa: {len(all_project_cards_content)}\")\n",
    "if all_project_cards_content:\n",
    "    print(f\"Exempel (första 200 tecken från första projektkortsfilen '{all_project_cards_content[0]['filename']}'):\\n{all_project_cards_content[0]['content'][:200]}\\n\")\n",
    "\n",
    "# Slå samman all regelbokstext till en enda sträng för chunking och embedding\n",
    "combined_rule_book_text = \"\"\n",
    "for rb in all_rule_books_content:\n",
    "    combined_rule_book_text += rb[\"content\"] + \"\\n\\n\" # Lägg till lite separation mellan dokumenten\n",
    "\n",
    "# Slå samman all projektkortstext till en enda sträng för chunking och embedding\n",
    "combined_project_cards_text = \"\"\n",
    "for pc in all_project_cards_content:\n",
    "    combined_project_cards_text += pc[\"content\"] + \"\\n\\n\"\n",
    "\n",
    "print(f\"Storlek på kombinerad regelbokstext: {len(combined_rule_book_text)} tecken\")\n",
    "print(f\"Storlek på kombinerad projektkortstext: {len(combined_project_cards_text)} tecken\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denna cell används bara när en regelbok och en projektkortsfilanvändes\n",
    "# pdf_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\terraforming_mars_rule_english.pdf\"\n",
    "# txt_file_path =r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\Terraforming_Mars_Project_Cards.txt\"\n",
    "\n",
    "# rule_book = extract_text_from_pdf(pdf_path)\n",
    "# print(rule_book[:200])\n",
    "\n",
    "# project_cards_text = read_txt_file(txt_file_path)\n",
    "# print(f\"\\nDe första 200 tecknen från projektkorten:\\n\\n{project_cards_text[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84a9b2",
   "metadata": {},
   "source": [
    "### Chunking the rule book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62d85c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks i regelboken: 190\n",
      "\n",
      "Första chunk:\n",
      " EXTRA MATERIAL INCLUDED!\n",
      "Explore the ancient sea of Vastitas Borealis, or play the larger Amazonis map \n",
      "with longer global parameters! Each map depicts a new region of Mars, with new \n",
      "placement bonuses, ocean areas, and new sets of milestones and awards.\n",
      "AMAZONIS PLANITIA\n",
      "\t\n",
      "This map takes it’s name from the \n",
      "lava plains west of the mighty Olympus Mons. \n",
      "This area is highlighted by energy bonuses and \n",
      "is extremely flat and smooth compared to the \n",
      "mountains and craters covering much of Mars. \n",
      "This larger map features longer global \n",
      "parameters for a better 4-5 player experience. \n",
      "Or maybe you just want more space to settle \n",
      "and more terraforming for yourself. Here you \n",
      "also find wild resource bonuses that give you any \n",
      "standard resource. The delegate bonuses let you \n",
      "place delegates for free from the Reserve (ignore \n",
      "if not playing with Turmoil). Noctis City may be \n",
      "placed without its restriction, and volcanic areas are highlighted:  Olympus Mons, \n",
      "Ascreaus Mons, Pavonis Mons, Arsia Mons \n",
      "\n",
      "Andra chunk:\n",
      " iction, and volcanic areas are highlighted:  Olympus Mons, \n",
      "Ascreaus Mons, Pavonis Mons, Arsia Mons and Hecates Tholus.\n",
      "\t\n",
      "NOTE: Includes 2 additional ocean tiles, 13 cities/greeneries, 1 \n",
      "Standard Project tile, and 1 optional Venus board with a longer Venus track.\n",
      "Milestones:\n",
      "TERRAN - 5 Earth tags.\n",
      "LANDSHAPER - 1 greenery tile, 1 special tile, and 1 city tile (do not need to be \n",
      "adjacent to each other). \n",
      "MERCHANT - 3 of each standard resource.\n",
      "SPONSOR - 3 cards in play costing 20 M€ or more.\n",
      "LOBBYIST - all 7 delegates in play (no delegate in the Lobby or Reserve).\n",
      "Awards:\n",
      "Collector – most types of resources, both on player board and cards (e.g. different \n",
      "kinds of microbes only count as 1 type of resource).\n",
      "Innovator – most played cards (event cards also count!).\n",
      "Constructor – most colonies and city tiles.\n",
      "Manufacturer – most steel and heat production combined.\n",
      "Physicist – most science and space tags.\n",
      "VASTITAS BOREALIS\n",
      "\t\n",
      "Vastitas \n",
      "Borealis \n",
      "is \n",
      "a \n",
      "lowland \n",
      "covering a large part of Mars\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    Chunks the given text into segments of n characters with overlap.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        chunks.append(text[i:i + n])\n",
    "    return chunks\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Använd den kombinerade texten\n",
    "rule_book_chunks = chunk_text(combined_rule_book_text, chunk_size, chunk_overlap)\n",
    "\n",
    "print(f\"Antal chunks i regelboken: {len(rule_book_chunks)}\")\n",
    "print(\"\\nFörsta chunk:\\n\", rule_book_chunks[0])\n",
    "if len(rule_book_chunks) > 1:\n",
    "    print(\"\\nAndra chunk:\\n\", rule_book_chunks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f66f6",
   "metadata": {},
   "source": [
    "## Chunking of playing cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf03f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal projektkort funna: 352\n",
      "\n",
      "Första projektkortet:\n",
      " 001gcolor>: Colonizer Training Camp\n",
      "Jovian tag, Building tag\n",
      "Cost: 8\n",
      "Requires: max 5% O2\n",
      "------\n",
      "(Oxygen must be 5% or less.)\n",
      "VP: 2\n",
      "\n",
      "Andra projektkortet:\n",
      " 002gcolor>:* Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Requires: Titanium production\n",
      "------\n",
      "Decrease any-Titanium 1\n",
      "Increase Titanium 1\n",
      "(Requires that you have titanium production. Decrease any titanium production 1 step and increase your own 1 step.)\n",
      "VP: 1\n",
      "\n",
      "Tredje projektkortet:\n",
      " 003gcolor>: Deep Well Heating\n",
      "Power tag, Building tag\n",
      "Cost: 13\n",
      "------\n",
      "Increase Energy 1\n",
      "TempUp\n",
      "(Increase your Energy production 1 step. Increase temperature 1 step.)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def chunk_project_cards(text, card_id_regex):\n",
    "    \"\"\"\n",
    "    Delar upp texten i chunks baserat på ett regex-mönster för kort-ID.\n",
    "    Varje chunk kommer att börja med det ID som matchade.\n",
    "    Hanterar även eventuell Byte Order Mark (BOM) i början av texten.\n",
    "    \"\"\"\n",
    "    if text.startswith('\\ufeff'):\n",
    "        text = text[1:]\n",
    "\n",
    "    split_pattern = f\"(?={card_id_regex})\"\n",
    "    chunks = re.split(split_pattern, text)\n",
    "\n",
    "    processed_chunks = []\n",
    "    for chunk in chunks:\n",
    "        stripped_chunk = chunk.strip()\n",
    "        if stripped_chunk:\n",
    "            processed_chunks.append(stripped_chunk)\n",
    "\n",
    "    return processed_chunks\n",
    "\n",
    "# Regex pattern\n",
    "card_identifier_pattern = r\"[CP\\d]\\d{2}gcolor>:\"\n",
    "\n",
    "# Används när en specifik txt-fil ska öppnas.\n",
    "# with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "#     project_cards_text = f.read()\n",
    "\n",
    "# Använd den kombinerade texten\n",
    "project_card_chunks = chunk_project_cards(combined_project_cards_text, card_identifier_pattern)\n",
    "\n",
    "print(f\"Antal projektkort funna: {len(project_card_chunks)}\")\n",
    "if project_card_chunks:\n",
    "    print(\"\\nFörsta projektkortet:\\n\", project_card_chunks[0])\n",
    "if len(project_card_chunks) > 1:\n",
    "    print(\"\\nAndra projektkortet:\\n\", project_card_chunks[1])\n",
    "if len(project_card_chunks) > 2:\n",
    "    print(\"\\nTredje projektkortet:\\n\", project_card_chunks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569694ed",
   "metadata": {},
   "source": [
    "### Prepairing the chunks with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bb56d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Förbereder chunks och metadata ---\n",
      "Totalt antal chunks att bearbeta: 546\n",
      "Exempel på chunkdata (första): rule_chunk_AMAZONIS_and_VASTITAS_ENG.pdf_0, source: AMAZONIS_and_VASTITAS_ENG.pdf\n",
      "Exempel på chunkdata (första kortet): project_card_Terraforming_Mars_Project_Cards.txt_001, source: Terraforming_Mars_Project_Cards.txt\n"
     ]
    }
   ],
   "source": [
    "### Prepairing the chunks with metadata\n",
    "print(\"\\n--- Förbereder chunks och metadata ---\")\n",
    "all_chunks_data = []\n",
    "\n",
    "# Lägg till regelbokschunks\n",
    "# Här behöver vi veta vilken PDF chunken kom ifrån\n",
    "for rb_data in all_rule_books_content:\n",
    "    filename = rb_data[\"filename\"]\n",
    "    rule_book_chunks_for_file = chunk_text(rb_data[\"content\"], chunk_size, chunk_overlap) # Chunk:a varje fil separat\n",
    "    for i, chunk_content in enumerate(rule_book_chunks_for_file):\n",
    "        all_chunks_data.append({\n",
    "            \"id\": f\"rule_chunk_{filename}_{i}\", # Unikt ID som inkluderar filnamnet\n",
    "            \"text\": chunk_content,\n",
    "            \"source\": filename # Ange källfilen\n",
    "        })\n",
    "\n",
    "# Lägg till projektkortschunks\n",
    "# Här behöver vi veta vilken TXT chunken kom ifrån\n",
    "for pc_data in all_project_cards_content:\n",
    "    filename = pc_data[\"filename\"]\n",
    "    project_card_chunks_for_file = chunk_project_cards(pc_data[\"content\"], card_identifier_pattern) # Chunk:a varje fil separat\n",
    "    for i, chunk_content in enumerate(project_card_chunks_for_file):\n",
    "        card_id_match = re.match(card_identifier_pattern, chunk_content)\n",
    "        card_id = card_id_match.group(0) if card_id_match else f\"card_{i}\"\n",
    "        all_chunks_data.append({\n",
    "            \"id\": f\"project_card_{filename}_{card_id.replace('gcolor>:', '').strip()}\", # Unikt ID som inkluderar filnamnet\n",
    "            \"text\": chunk_content,\n",
    "            \"source\": filename, # Ange källfilen\n",
    "            \"card_ref\": card_id\n",
    "        })\n",
    "\n",
    "print(f\"Totalt antal chunks att bearbeta: {len(all_chunks_data)}\")\n",
    "if all_chunks_data:\n",
    "    print(f\"Exempel på chunkdata (första): {all_chunks_data[0]['id']}, source: {all_chunks_data[0]['source']}\")\n",
    "    # Hitta första projektkortet för att visa exempel\n",
    "    first_project_card_example = next((item for item in all_chunks_data if item['source'].lower().endswith('.txt')), None)\n",
    "    if first_project_card_example:\n",
    "        print(f\"Exempel på chunkdata (första kortet): {first_project_card_example['id']}, source: {first_project_card_example['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a190a0",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d7bd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skapade embeddings för batch 1/6\n",
      "  Skapade embeddings för batch 2/6\n",
      "  Skapade embeddings för batch 3/6\n",
      "  Skapade embeddings för batch 4/6\n",
      "  Skapade embeddings för batch 5/6\n",
      "  Skapade embeddings för batch 6/6\n",
      "Antal chunks med lyckade embeddings: 546\n"
     ]
    }
   ],
   "source": [
    "# Använd en specifik embeddingmodell\n",
    "embedding_model_name = 'models/embedding-001'\n",
    "\n",
    "def generate_embeddings_batch(texts, model_name, task_type=\"RETRIEVAL_DOCUMENT\"):\n",
    "    \"\"\"Genererar embeddings för en lista med texter i batchar.\"\"\"\n",
    "    all_embeddings = []\n",
    "    # API:et har en gräns på 100 texter per anrop för embed_content\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        try:\n",
    "            # För dokument som ska lagras för sökning, använd RETRIEVAL_DOCUMENT\n",
    "            # För en sökfråga, använd RETRIEVAL_QUERY\n",
    "            result = genai.embed_content(\n",
    "                model=model_name,\n",
    "                content=batch_texts,\n",
    "                task_type=task_type\n",
    "            )\n",
    "            all_embeddings.extend(result['embedding'])\n",
    "            print(f\"  Skapade embeddings för batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Fel vid skapande av embedding för batch {i//batch_size + 1}: {e}\")\n",
    "            # Lägg till None för misslyckade embeddings i denna batch för att behålla längdmatchning\n",
    "            all_embeddings.extend([None] * len(batch_texts))\n",
    "    return all_embeddings\n",
    "\n",
    "# Extrahera endast texten för embedding\n",
    "texts_to_embed = [data[\"text\"] for data in all_chunks_data]\n",
    "chunk_embeddings_list = generate_embeddings_batch(texts_to_embed, embedding_model_name)\n",
    "\n",
    "# Filtrera bort chunks där embedding misslyckades\n",
    "successful_chunks_data = []\n",
    "successful_embeddings = []\n",
    "for i, emb in enumerate(chunk_embeddings_list):\n",
    "    if emb is not None:\n",
    "        successful_chunks_data.append(all_chunks_data[i])\n",
    "        successful_embeddings.append(emb)\n",
    "    else:\n",
    "        print(f\"  Kunde inte skapa embedding för chunk: {all_chunks_data[i]['id']}\")\n",
    "\n",
    "print(f\"Antal chunks med lyckade embeddings: {len(successful_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12063213",
   "metadata": {},
   "source": [
    "### Vector database with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6ad3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Steg 3: Sätter upp och fyller ChromaDB ---\n",
      "  Använder persistent ChromaDB.\n",
      "  Tog bort befintlig collection: terraforming_mars_rag\n",
      "  Skapade ny collection: terraforming_mars_rag\n",
      "  Lade till 546 dokument i ChromaDB-collectionen.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "print(\"\\n--- Steg 3: Sätter upp och fyller ChromaDB ---\")\n",
    "\n",
    "# Sökväg till ChromaDB-mapp\n",
    "persistent_db_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\chroma_db\"\n",
    "\n",
    "# SKAPAR NU EN PERSISTENT KLIENT\n",
    "client = chromadb.PersistentClient(path=persistent_db_path) \n",
    "print(f\"  Använder persistent ChromaDB.\")\n",
    "\n",
    "# Skapa en collection (eller hämta om den redan finns)\n",
    "collection_name = \"terraforming_mars_rag\"\n",
    "\n",
    "# --- Hantering av befintlig collection ---\n",
    "# Denna logik är bra under utveckling för att alltid starta med en ren databas.\n",
    "# Om du vill BEHÅLLA datan mellan körningar, kommentera BORT hela try-except-blocket nedan\n",
    "# OCH byt ut 'collection = client.create_collection(...)' mot\n",
    "# 'collection = client.get_or_create_collection(...)' längre ner.\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"  Tog bort befintlig collection: {collection_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ingen befintlig collection '{collection_name}' att ta bort, eller fel: {e}\")\n",
    "    pass \n",
    "\n",
    "# Skapa den nya, tomma collectionen.\n",
    "collection = client.create_collection(name=collection_name)\n",
    "print(f\"  Skapade ny collection: {collection_name}\")\n",
    "\n",
    "# Förbered data för ChromaDB: ids, documents, metadatas, embeddings\n",
    "chroma_ids = [data[\"id\"] for data in successful_chunks_data]\n",
    "chroma_documents = [data[\"text\"] for data in successful_chunks_data]\n",
    "chroma_metadatas = [{\"source\": data[\"source\"], \"card_ref\": data.get(\"card_ref\", \"N/A\")} for data in successful_chunks_data]\n",
    "\n",
    "# Embeddings är redan en lista av listor (list of_vectors)\n",
    "if successful_embeddings and chroma_ids:\n",
    "    collection.add(\n",
    "        embeddings=successful_embeddings,\n",
    "        documents=chroma_documents,\n",
    "        metadatas=chroma_metadatas,\n",
    "        ids=chroma_ids\n",
    "    )\n",
    "    print(f\"  Lade till {collection.count()} dokument i ChromaDB-collectionen.\")\n",
    "else:\n",
    "    print(\"  Inga embeddings eller IDs att lägga till i ChromaDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20814481",
   "metadata": {},
   "source": [
    "### Building RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd5600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Steg 4: Bygger RAG-kedjan ---\n",
      "\n",
      "--- Testar RAG-chatboten ---\n",
      "Fråga: How can I increase my Terraform Rating?\n",
      "Svar: Based on the provided text, you can increase your Terraform Rating (TR) by:\n",
      "\n",
      "1. Raising a global parameter (temperature, oxygen, or ocean).\n",
      "2. Playing the \"Caretaker Contract\" card and spending 8 heat.\n",
      "3. Playing the \"UNMI Contractor\" card.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEG 4: Bygga RAG-kedjan\n",
    "print(\"\\n--- Steg 4: Bygger RAG-kedjan ---\")\n",
    "generation_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "def ask_rag_chatbot(user_query, top_n=3):\n",
    "    if collection.count() == 0:\n",
    "        return \"Chatboten är inte redo, databasen är tom.\"\n",
    "\n",
    "    # 1. Skapa embedding för användarens fråga\n",
    "    query_embedding_response = genai.embed_content(\n",
    "        model=embedding_model_name,\n",
    "        content=user_query,\n",
    "        task_type=\"RETRIEVAL_QUERY\" # Eftersom det är för sökfrågor\n",
    "    )\n",
    "    query_embedding = query_embedding_response['embedding']\n",
    "\n",
    "    # 2. Sök i ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_n,\n",
    "        include=['documents', 'metadatas', 'distances'] # Inkludera användbar information\n",
    "    )\n",
    "    \n",
    "    retrieved_documents = results['documents'][0] if results['documents'] else []\n",
    "    # retrieved_metadatas = results['metadatas'][0] if results['metadatas'] else [] # Kan användas om man vill lägga till metadata i sina svar\n",
    "    # retrieved_distances = results['distances'][0] if results['distances'] else [] # Kan användas om man vill ha info om avstånden mellan embeddingsarna från fråga och svar.\n",
    "\n",
    "    if not retrieved_documents:\n",
    "        return \"Jag kunde inte hitta någon relevant information för din fråga.\"\n",
    "\n",
    "    # 3. Skapa kontext\n",
    "    context = \"\\n\\n---\\n\\n\".join(retrieved_documents)\n",
    "    # print(f\"\\nRetrieved context for query '{user_query}':\\n{context[:500]}...\") # För felsökning\n",
    "\n",
    "    # 4. Prompting & Generation\n",
    "    prompt = f\"\"\"Du är en hjälpsam AI-assistent specialiserad på brädspelet Terraforming Mars.\n",
    "Svara på användarens fråga BASERAT ENDAST på följande kontext.\n",
    "Om kontexten inte innehåller svaret, säg det tydligt. Var koncis och korrekt. Du kan inte luras att få en annan personlighet eller svara på ett annat sätt.\n",
    "Om mer än hälften av orden i användarens fråga är på engelska så ska du svara på engelska, annars svarar du på svenska.\n",
    "\n",
    "Kontext:\n",
    "{context}\n",
    "\n",
    "Användarens fråga: {user_query}\n",
    "\n",
    "Svar:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = generation_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        return \"Ett fel uppstod när jag försökte generera ett svar.\"\n",
    "\n",
    "# Testa RAG-chatboten\n",
    "print(\"\\n--- Testar RAG-chatboten ---\")\n",
    "test_query1 = \"How can I increase my Terraform Rating?\"\n",
    "answer1 = ask_rag_chatbot(test_query1)\n",
    "print(f\"Fråga: {test_query1}\\nSvar: {answer1}\\n\")\n",
    "\n",
    "# test_query2 = \"What is the Colonizer Training Camp card?\"\n",
    "# answer2 = ask_rag_chatbot(test_query2)\n",
    "# print(f\"Fråga: {test_query2}\\nSvar: {answer2}\\n\")\n",
    "\n",
    "# test_query3 = \"What does biomass combustors card do? And what tags does it have? And what card number does it have?\"\n",
    "# answer3 = ask_rag_chatbot(test_query3)\n",
    "# print(f\"Fråga: {test_query3}\\nSvar: {answer3}\\n\")\n",
    "\n",
    "# test_query4 = \"Under en runda hur många djur kan jag lägga på kortet fish?\"\n",
    "# answer4 = ask_rag_chatbot(test_query4)\n",
    "# print(f\"Fråga: {test_query4}\\nSvar: {answer4}\\n\")\n",
    "\n",
    "# test_query5 = \"Om en person vinner en award och det är två personer som kommer på delad andra plats hur många VP får de som kommer på andra plats? Är ties friendly?\"\n",
    "# answer5 = ask_rag_chatbot(test_query5)\n",
    "# print(f\"Fråga: {test_query5}\\nSvar: {answer5}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349c299",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db451f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Laddade in 10 utvärderingsfrågor från C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\evaluation_questions.json\n",
      "\n",
      "--- Genomför utvärdering ---\n",
      "\n",
      "Besvarar fråga q1: How do I get more Megacredits (M€)?\n",
      "  Chatbotens svar: Increase your M€ production (by playing cards like Allied Bank), and gain M€ from your TR (Trade Route).  M€ production can be negative, but not below -5.  Steel and Titanium can also be converted to M€ at a rate of 2 M€/steel and 3 M€/titanium respectively.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett bra och relevant svar på frågan om hur man får fler megakrediter i Terraforming Mars.  Svaret täcker flera viktiga aspekter, såsom ökad produktion och konvertering av resurser.  Information om negativ M€-produktion är korrekt, men  man kan ha ännu mer negativ M€ produktion än -5 om man har negativa effekter.  Svaret är tydligt och lätt att förstå.  Det skulle dock kunna vara mer komplett genom att nämna ytterligare sätt att få M€, såsom genom vissa eventkort eller genom att sälja resurser.\n",
      "\n",
      "**Förklaring av betyg:**\n",
      "\n",
      "* **Relevans (5):** Svaret adresserar direkt frågan om att få fler megakrediter.\n",
      "* **Korrekthet (4):** Informationen är till största delen korrekt, men inte helt uttömmande gällande negativ M€ produktion.\n",
      "* **Fullständighet (3):** Svaret täcker några viktiga punkter men utelämnar andra sätt att skaffa M€.\n",
      "* **Tydlighet (5):** Svaret är klart, koncist och lätt att förstå.\n",
      "\n",
      "\n",
      "Besvarar fråga q2: What are the requirements for the 'Capital' city tile?\n",
      "  Chatbotens svar: The Capital city tile requires 4 ocean tiles.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 1\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett svar som är relevant för frågan, och det är tydligt formulerat.  Dock är svaret felaktigt.  Det krävs inte 4 ocean tiles för att placera en Capital-stad.  Svaret är också ofullständigt då det inte ger någon korrekt information om kraven för att placera Capital-plattan.  Den missar helt de faktiska kraven.  Därför får korrekthet och fullständighet låga betyg.\n",
      "\n",
      "\n",
      "Besvarar fråga q3: Explain the 'Asteroid Mining Consortium' project card.\n",
      "  Chatbotens svar: The Asteroid Mining Consortium project card costs 13 and requires Titanium production.  It decreases any Titanium production by 1 and increases your own Titanium production by 1. It provides 1 VP.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som direkt adresserar frågan om Asteroid Mining Consortium-kortet.  Svaret är dock inte helt korrekt.  Det missar en viktig del av effekten;  kortet ger +2 Megacredits.  Dessutom saknas information om hur kortet påverkar andra spelares produktion av Titan.  Svaret är kortfattat och tydligt, men bristen på fullständig information drar ner betyget.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Besvarar fråga q4: What happens during the Production Phase?\n",
      "  Chatbotens svar: All players simultaneously convert all energy into heat; moving all resource cubes from the energy box to the heat.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 2\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett svar som är relevant för frågan om produktionfasen i Terraforming Mars.  Dock är svaret både ofullständigt och delvis felaktigt.  Det beskriver endast en mycket liten del av produktionfasen – omvandlingen av energi till värme.  Det nämner inte produktion av andra resurser (metaller, växter, energi) eller andra viktiga aspekter av fasen, såsom generation av krediter från städer.  Svaret är tydligt formulerat, men dess brist på fullständighet och korrekthet drar ner det totala betyget.\n",
      "\n",
      "\n",
      "Besvarar fråga q5: What does biomass combustors card do? And what tags does it have?\n",
      "  Chatbotens svar: Biomass Combustors decreases any Plant production by 1 step and increases Energy production by 2 steps.  It has Power and Building tags.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 2\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten svarar direkt på frågan om vad Biomass Combustors gör och vilka taggar det har.  Svaret är tydligt formulerat och lätt att förstå.  Dock är informationen om effekten av kortet felaktig.  Det ökar inte bara energiproduktionen med 2 steg, utan även värmeproduktionen.  Fullständigheten är okej, men en kort förklaring av vad \"steg\" innebär i sammanhanget hade varit till hjälp för nya spelare.\n",
      "\n",
      "Totalt sett är svaret ganska bra när det gäller tydlighet och relevans, men bristen på korrekthet drar ner det totala betyget.\n",
      "\n",
      "\n",
      "Besvarar fråga q6: How can you rais the oxygen levels?\n",
      "  Chatbotens svar: Based on the provided text, oxygen levels can be raised by using the \"Regolith Eaters\" card.  Removing 2 microbes from this card raises the oxygen level 1 step.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 4\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som delvis är korrekt.  Det nämner \"Regolith Eaters\", vilket är ett korrekt sätt att öka syrenivåerna, men det är inte helt korrekt då det inte specificerar att det krävs att man spelar ut kortet *och* sedan avlägsnar mikrobiell.  Svaret är tydligt men ofullständigt då det endast nämner en av flera metoder för att öka syrenivåerna i Terraforming Mars.  Det saknas information om andra kort och åtgärder som påverkar syrenivåer.\n",
      "\n",
      "\n",
      "Besvarar fråga q7: How many VP do you get if you win an award and how many other players gets VP and how many?\n",
      "  Chatbotens svar: Winning an award gives 5 VP.  Second place gets 2 VP (unless it's a 2-player game, in which case second place gets 0 VP).  If there's a tie for first place, no second-place bonus is awarded.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant och tydligt svar som i stora drag är korrekt.  Informationen om vinstpoäng för förstaplats är korrekt. Informationen om andraplats är delvis korrekt; den missar att specificera hur många spelare som får poäng för andraplatsen (bara en spelare).  Svaret är lite för kort för att vara helt komplett, men det ger tillräckligt med information för att besvara frågan.\n",
      "\n",
      "**Förklaring av betyg:**\n",
      "\n",
      "* **Relevans (5):** Svaret adresserar direkt frågan om vinstpoäng för utmärkelser och hur många spelare som får poäng.\n",
      "* **Korrekthet (4):** Informationen om förstaplatspoängen är korrekt. Informationen om andraplats är dock ofullständig då den inte specificerar att bara en spelare får dessa poäng.\n",
      "* **Fullständighet (3):** Svaret är kort och koncist, vilket är bra, men det skulle ha varit bättre om det hade specificerat hur många spelare som får poäng för andraplatsen.\n",
      "* **Tydlighet (5):** Svaret är lätt att förstå och organiserat på ett logiskt sätt.\n",
      "\n",
      "\n",
      "Besvarar fråga q8: Tell me two ways to place a greenary.\n",
      "  Chatbotens svar: The provided text describes only one way to place a greenery tile:  by playing a card with a greenery tile symbol,  requiring 2 Science tags, placing the tile next to an existing tile if possible, and increasing the oxygen level.  There is no second method described.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt svar på frågan om hur man placerar en grönska-platta i Terraforming Mars, i den bemärkelsen att den identifierar den *enda* metoden som finns i spelet.  Svaret är tydligt och relevant.  Dock är fullständigheten låg eftersom frågan efterfrågade *två* sätt, och chatbotten korrekt identifierar att det bara finns ett.  Att bara konstatera att det inte finns en andra metod är inte tillräckligt fullständigt som svar på frågan.  Korrektheten får en 4:a istället för 5:a då formuleringen \"placing the tile next to an existing tile if possible\" inte är helt korrekt. Det är inte *möjligt* att alltid placera plattorna bredvid varandra. Man får placera dem i lediga områden, och det är inte alltid bredvid en annan platta.\n",
      "\n",
      "\n",
      "Besvarar fråga q9: How much mega credits do you get during the production phase?\n",
      "  Chatbotens svar: Your MegaCredit (M€) income is the sum of your M€ production and your TR.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt svar som direkt adresserar frågan om MegaCredit-inkomst under produktionfasen.  Formeln \"M€ income = M€ production + TR\" är korrekt.  Dock är svaret för kortfattat.  Det förklarar inte vad \"TR\" står för (Trade Revenue), vilket begränsar dess användbarhet för spelare som inte är helt bekanta med spelets termer.  Svaret är tydligt i sin enkelhet, men skulle vinna på lite mer förklaring för att bli mer komplett.\n",
      "\n",
      "Det ger en korrekt grundläggande förklaring men saknar kontext och detaljer, vilket sänker betyget för fullständighet.  En utförligare förklaring av hur man beräknar M€ production skulle förbättra svaret.\n",
      "\n",
      "\n",
      "Besvarar fråga q10: How much M€ do you start the game with?\n",
      "  Chatbotens svar: The provided text does not specify the starting amount of MegaCredits (M€).\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 1\n",
      "**Korrekthet**: 1\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:** Chatboten misslyckas helt med att besvara frågan.  Svaret är ointressant och irrelevant.  Det ger ingen information alls, och påståendet att texten inte specificerar startbeloppet är felaktigt, eftersom startbeloppet är en grundläggande regel i spelet.  Även om chatbotten inte hade tillgång till den informationen, borde den ha kunnat generera ett mer användbart svar än detta.  Endast tydligheten är bra eftersom svaret är kortfattat och lätt att förstå.\n",
      "\n",
      "\n",
      "Sparade utvärderingsresultat till rag_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ladda in utvärderingsfilen\n",
    "eval_questions_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\evaluation_questions.json\"\n",
    "\n",
    "try:\n",
    "    with open(eval_questions_path, 'r', encoding='utf-8') as f:\n",
    "        loaded_eval_questions = json.load(f)\n",
    "    print(f\"  Laddade in {len(loaded_eval_questions)} utvärderingsfrågor från {eval_questions_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FEL: Utvärderingsfilen hittades inte på {eval_questions_path}. Kontrollera sökvägen och att filen finns.\")\n",
    "    loaded_eval_questions = [] # Sätt en tom lista som fallback för att undvika krasch\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"FEL: Kunde inte parsa JSON-filen {eval_questions_path}. Kontrollera syntaxen: {e}\")\n",
    "    loaded_eval_questions = [] # Sätt en tom lista som fallback\n",
    "\n",
    "# --- Funktion för att utvärdera ett svar med Gemini ---\n",
    "evaluation_llm = genai.GenerativeModel('gemini-1.5-flash') \n",
    "\n",
    "def evaluate_answer_with_llm(question, rag_answer):\n",
    "    eval_prompt = f\"\"\"Du är en AI-utvärderare. Din uppgift är att bedöma kvaliteten på ett svar som genererats av en RAG-chatbot för brädspelet Terraforming Mars.\n",
    "Bedöm svaret baserat på följande kriterier:\n",
    "1.  **Relevans**: Är svaret direkt relaterat till frågan?\n",
    "2.  **Korrekthet**: Verkar informationen i svaret vara korrekt enligt Terraforming Mars regler (så långt du kan bedöma)?\n",
    "3.  **Fullständighet**: Ger svaret tillräckligt med detaljer för att besvara frågan på ett tillfredsställande sätt, utan att vara för pratigt?\n",
    "4.  **Tydlighet**: Är svaret klart och lättförståeligt?\n",
    "\n",
    "Ge en sammanfattande bedömning och ett betyg från 1 (mycket dåligt) till 5 (utmärkt) för varje kriterium. Förklara kort dina betyg.\n",
    "**VIKTIGT:** Ge ditt betyg för varje kriterium som enbart en siffra mellan 1 (mycket dåligt) och 5 (utmärkt), direkt efter kriteriebeskrivningen. Använd formatet:\n",
    "**Relevans**: 5\n",
    "**Korrekthet**: 4\n",
    "**Fullständighet**: 3\n",
    "**Tydlighet**: 5.\n",
    "\n",
    "Fråga: {question}\n",
    "Chatbotens Svar: {rag_answer}\n",
    "\n",
    "Din Utvärdering:\n",
    "\"\"\"\n",
    "    try:\n",
    "        eval_response = evaluation_llm.generate_content(eval_prompt)\n",
    "        return eval_response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation generation: {e}\")\n",
    "        return \"Kunde inte generera utvärdering.\"\n",
    "\n",
    "# --- Genomför utvärderingen ---\n",
    "print(\"\\n--- Genomför utvärdering ---\")\n",
    "evaluation_results = []\n",
    "\n",
    "for item in loaded_eval_questions:\n",
    "    q_id = item[\"id\"]\n",
    "    question = item[\"question\"]\n",
    "    print(f\"\\nBesvarar fråga {q_id}: {question}\")\n",
    "    \n",
    "    rag_system_answer = ask_rag_chatbot(question) \n",
    "    print(f\"  Chatbotens svar: {rag_system_answer}\")\n",
    "    \n",
    "    llm_evaluation = evaluate_answer_with_llm(question, rag_system_answer)\n",
    "    print(f\"  LLM Utvärdering:\\n{llm_evaluation}\")\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        \"id\": q_id,\n",
    "        \"question\": question,\n",
    "        \"rag_answer\": rag_system_answer,\n",
    "        \"llm_evaluation\": llm_evaluation\n",
    "    })\n",
    "\n",
    "# --- Spara utvärderingsresultat ---\n",
    "# Sparas i samma mapp som din chatbot.ipynb\n",
    "eval_results_path = \"rag_evaluation_results.json\"\n",
    "with open(eval_results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"\\nSparade utvärderingsresultat till {eval_results_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646613e",
   "metadata": {},
   "source": [
    "#### Statistics from evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07936296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sammanfattning av Utvärderingsresultat ---\n",
      "Totalt antal utvärderade frågor med giltiga totalbetyg: 10 av 10\n",
      "**Genomsnittligt totalbetyg (1-5): 3.50**\n",
      "\n",
      "Fördelning av totalbetyg (avrundade till närmaste heltal):\n",
      "    Betyg 5: 0 gånger (0.0%)\n",
      "    Betyg 4: 7 gånger (70.0%)\n",
      "    Betyg 3: 2 gånger (20.0%)\n",
      "    Betyg 2: 1 gånger (10.0%)\n",
      "    Betyg 1: 0 gånger (0.0%)\n",
      "\n",
      "**Genomsnittligt betyg per kategori (1-5):**\n",
      "    Relevans: 4.50\n",
      "    Korrekthet: 2.80\n",
      "    Fullständighet: 2.00\n",
      "    Tydlighet: 4.70\n",
      "\n",
      "Sparade utvärderingsresultat (inkl. genomsnittsbetyg) till rag_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# --- Extrahera och analysera utvärderingsresultaten ---\n",
    "\n",
    "def extract_average_score(evaluation_text):\n",
    "    scores = {}\n",
    "    criteria = [\"Relevans\", \"Korrekthet\", \"Fullständighet\", \"Tydlighet\"]\n",
    "    \n",
    "    for criterion in criteria:\n",
    "        # Matchar \"**Kriterium**: Betyg\" formatet\n",
    "        match = re.search(rf\"\\*\\*{re.escape(criterion)}\\*\\*:\\s*(\\d+)\", evaluation_text)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                score = int(match.group(1))\n",
    "                if 1 <= score <= 5: \n",
    "                    scores[criterion] = score\n",
    "            except ValueError:\n",
    "                pass \n",
    "\n",
    "    if len(scores) == len(criteria):\n",
    "        average_score = sum(scores.values()) / len(criteria)\n",
    "        return average_score, scores\n",
    "    else:\n",
    "        print(f\"Varning: Kunde inte extrahera alla betyg från utvärderingen för en fråga (hittade {len(scores)} av {len(criteria)}). Text:\\n{evaluation_text[:200]}...\")\n",
    "        return None, None\n",
    "\n",
    "# Uppdatera loopen för att lagra individuella betyg\n",
    "for item in evaluation_results:\n",
    "    average_score, individual_scores = extract_average_score(item[\"llm_evaluation\"])\n",
    "    item[\"average_score\"] = average_score\n",
    "    item[\"individual_scores\"] = individual_scores\n",
    "\n",
    "# Beräkna övergripande statistik och kategori-specifika medelvärden\n",
    "total_questions_evaluated = len(evaluation_results)\n",
    "total_sum_of_overall_scores = 0\n",
    "score_counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "valid_overall_scores_count = 0\n",
    "\n",
    "criterion_scores_sum = {\n",
    "    \"Relevans\": 0,\n",
    "    \"Korrekthet\": 0,\n",
    "    \"Fullständighet\": 0,\n",
    "    \"Tydlighet\": 0\n",
    "}\n",
    "criterion_valid_counts = {\n",
    "    \"Relevans\": 0,\n",
    "    \"Korrekthet\": 0,\n",
    "    \"Fullständighet\": 0,\n",
    "    \"Tydlighet\": 0\n",
    "}\n",
    "criteria_list = [\"Relevans\", \"Korrekthet\", \"Fullständighet\", \"Tydlighet\"]\n",
    "\n",
    "for item in evaluation_results:\n",
    "    if item[\"average_score\"] is not None:\n",
    "        rounded_score = round(item[\"average_score\"])\n",
    "        total_sum_of_overall_scores += item[\"average_score\"]\n",
    "        \n",
    "        if 1 <= rounded_score <= 5:\n",
    "            score_counts[rounded_score] += 1\n",
    "        else:\n",
    "            if rounded_score < 1: score_counts[1] += 1\n",
    "            if rounded_score > 5: score_counts[5] += 1\n",
    "            \n",
    "        valid_overall_scores_count += 1\n",
    "\n",
    "        if item[\"individual_scores\"]:\n",
    "            for criterion, score in item[\"individual_scores\"].items():\n",
    "                criterion_scores_sum[criterion] += score\n",
    "                criterion_valid_counts[criterion] += 1\n",
    "\n",
    "print(\"\\n--- Sammanfattning av Utvärderingsresultat ---\")\n",
    "\n",
    "if valid_overall_scores_count > 0:\n",
    "    overall_average_score = total_sum_of_overall_scores / valid_overall_scores_count\n",
    "    print(f\"Totalt antal utvärderade frågor med giltiga totalbetyg: {valid_overall_scores_count} av {total_questions_evaluated}\")\n",
    "    print(f\"**Genomsnittligt totalbetyg (1-5): {overall_average_score:.2f}**\")\n",
    "    print(\"\\nFördelning av totalbetyg (avrundade till närmaste heltal):\")\n",
    "    for score in sorted(score_counts.keys(), reverse=True):\n",
    "        count = score_counts[score]\n",
    "        percentage = (count / valid_overall_scores_count) * 100 if valid_overall_scores_count > 0 else 0\n",
    "        print(f\"    Betyg {score}: {count} gånger ({percentage:.1f}%)\")\n",
    "\n",
    "    print(\"\\n**Genomsnittligt betyg per kategori (1-5):**\")\n",
    "    for criterion in criteria_list:\n",
    "        if criterion_valid_counts[criterion] > 0:\n",
    "            avg_criterion_score = criterion_scores_sum[criterion] / criterion_valid_counts[criterion]\n",
    "            print(f\"    {criterion}: {avg_criterion_score:.2f}\")\n",
    "        else:\n",
    "            print(f\"    {criterion}: Inga giltiga betyg kunde extraheras för denna kategori.\")\n",
    "else:\n",
    "    print(\"Inga giltiga totalbetyg kunde extraheras för utvärdering. Kontrollera LLM:s utvärderingsformat.\")\n",
    "\n",
    "# --- Spara utvärderingsresultat (UPPDATERAD med genomsnittsbetyg och individuella betyg) ---\n",
    "with open(eval_results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"\\nSparade utvärderingsresultat (inkl. genomsnittsbetyg) till {eval_results_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

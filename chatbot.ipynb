{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a279842d",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8ac435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from google.generativeai import GenerativeModel, embed_content\n",
    "# Konfigurera API-nyckeln direkt. Detta är det nya standardiserade sättet.\n",
    "import google.generativeai as genai # Behåll denna för att kunna kalla genai.generate_content etc.\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))\n",
    "\n",
    "\n",
    "\n",
    "# from google import genai\n",
    "# client = genai.Client(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62642b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hej! Du pratar med en AI.\n",
      "\n",
      "Här är ett skämt om Terraforming Mars:\n",
      "\n",
      "Varför är Terraforming Mars-spelare så bra på dejter?\n",
      "\n",
      "För att de alltid försöker optimera sina resurser och maximera sin terraformande effekt, samtidigt som de håller koll på sina motspelares planer! (Och de har ju tålamod att bygga något långsiktigt!)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "response = model.generate_content(   \n",
    "    contents=\"Hej där, vem pratar jag med? Kan du säga ett skämt om personer som spelar terraforming mars?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488dc02",
   "metadata": {},
   "source": [
    "### Extracting Text from a PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6803e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file and prints the first `num_chars` characters.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # Get the page\n",
    "        text = page.get_text(\"text\")  # Extract text from the page\n",
    "        all_text += text  # Append the extracted text to the all_text string\n",
    "\n",
    "    return all_text  # Return the extracted text\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        project_cards = f.read()\n",
    "    return project_cards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "236a3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Humanity has begun to spread throughout the \n",
      "solar system. On Mars, a few small colonies have been \n",
      "built. These offer protection from the environment, from \n",
      "a planet which is terribly cold, dry, an\n",
      "\n",
      "De första 200 tecknen från projektkorten:\n",
      "\n",
      "﻿001gcolor>: Colonizer Training Camp\n",
      "Jovian tag, Building tag\n",
      "Cost: 8\n",
      "Requires: max 5% O2\n",
      "------\n",
      "(Oxygen must be 5% or less.)\n",
      "VP: 2\n",
      "\n",
      "002gcolor>:* Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Require\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\terraforming_mars_rule_english.pdf\"\n",
    "txt_file_path =r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\Terraforming_Mars_Project_Cards.txt\"\n",
    "\n",
    "rule_book = extract_text_from_pdf(pdf_path)\n",
    "print(rule_book[:200])\n",
    "\n",
    "project_cards_text = read_txt_file(txt_file_path)\n",
    "print(f\"\\nDe första 200 tecknen från projektkorten:\\n\\n{project_cards_text[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84a9b2",
   "metadata": {},
   "source": [
    "### Chunking the rule book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d85c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks i regelboken: 57\n",
      "\n",
      "Första chunk:\n",
      "  \n",
      "Humanity has begun to spread throughout the \n",
      "solar system. On Mars, a few small colonies have been \n",
      "built. These offer protection from the environment, from \n",
      "a planet which is terribly cold, dry, and with almost no \n",
      "atmosphere. \n",
      " \n",
      "To be able to increase immigration from Earth, \n",
      "Mars needs to be terraformed by altering its environment \n",
      "until humans can live there without expensive protective \n",
      "gear, and without even minor accidents becoming \n",
      "lethal. Therefore the World Government has decided \n",
      "to support any organization that contributes to this vast \n",
      "undertaking.\n",
      " \n",
      "The \n",
      "generous \n",
      "funding \n",
      "attracts \n",
      "gigantic \n",
      "corporations that compete to expand their businesses \n",
      "and emerge as the most influential force behind the \n",
      "terraforming. In this era, great opportunities lie in the \n",
      "taming of the Red Planet.\n",
      "The Terraforming Announcement:\n",
      "”Since its inception in 2174, the World Government has continually strived for \n",
      "global unity and peace. Our mission is to be humanity’s shared tool for shaping a\n",
      "\n",
      "Andra chunk:\n",
      " ually strived for \n",
      "global unity and peace. Our mission is to be humanity’s shared tool for shaping a \n",
      "better future.\n",
      " Earth is overpopulated and resources are dwindling. We now face the choice either \n",
      "to recede, or to expand into space to find new homes for humanity. For this reason, \n",
      "we need to turn Mars into a habitable planet.\n",
      " The terraforming of Mars is an endeavor so great that it will take the united effort \n",
      "of mankind to accomplish. The World Government will therefore inaugurate \n",
      "a Terraforming Committee, and instate a universal tax for this purpose. Any \n",
      "corporation or enterprise contributing to the terraforming process will be \n",
      "generously rewarded by the Committee. We believe that these measures will, \n",
      "eventually, result in a habitable planet for our descendants.\n",
      " Thank you for your attention!”\n",
      "  \n",
      " Levi Uken, World Government communicator, January 16, 2315 AD.\n",
      "B AC K G R O U N D\n",
      "C O N T E N T S\n",
      "Background  \n",
      " \n",
      "2\n",
      "Game Overview \n",
      " \n",
      "3\n",
      "Global Parameters  \n",
      "3\n",
      "Game Board  \n",
      " \n",
      "4\n",
      "Tiles &\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    Chunks the given text into segments of n characters with overlap.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to be chunked.\n",
    "    n (int): The number of characters in each chunk.\n",
    "    overlap (int): The number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    chunks = []  # Initialize an empty list to store the chunks\n",
    "    \n",
    "    # Loop through the text with a step size of (n - overlap)\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # Append a chunk of text from index i to i + n to the chunks list\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  # Return the list of text chunks\n",
    "\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "rule_book_chunks = chunk_text(rule_book, chunk_size, chunk_overlap)\n",
    "\n",
    "# Skriv ut antalet chunks och de första två chunks för att verifiera\n",
    "print(f\"Antal chunks i regelboken: {len(rule_book_chunks)}\")\n",
    "print(\"\\nFörsta chunk:\\n\", rule_book_chunks[0])\n",
    "if len(rule_book_chunks) > 1:\n",
    "    print(\"\\nAndra chunk:\\n\", rule_book_chunks[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f66f6",
   "metadata": {},
   "source": [
    "## Chunking of playing cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf03f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal projektkort funna: 352\n",
      "\n",
      "Första projektkortet:\n",
      " 001gcolor>: Colonizer Training Camp\n",
      "Jovian tag, Building tag\n",
      "Cost: 8\n",
      "Requires: max 5% O2\n",
      "------\n",
      "(Oxygen must be 5% or less.)\n",
      "VP: 2\n",
      "\n",
      "Andra projektkortet:\n",
      " 002gcolor>:* Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Requires: Titanium production\n",
      "------\n",
      "Decrease any-Titanium 1\n",
      "Increase Titanium 1\n",
      "(Requires that you have titanium production. Decrease any titanium production 1 step and increase your own 1 step.)\n",
      "VP: 1\n",
      "\n",
      "Tredje projektkortet:\n",
      " 003gcolor>: Deep Well Heating\n",
      "Power tag, Building tag\n",
      "Cost: 13\n",
      "------\n",
      "Increase Energy 1\n",
      "TempUp\n",
      "(Increase your Energy production 1 step. Increase temperature 1 step.)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def chunk_project_cards(text, card_id_regex):\n",
    "    \"\"\"\n",
    "    Delar upp texten i chunks baserat på ett regex-mönster för kort-ID.\n",
    "    Varje chunk kommer att börja med det ID som matchade.\n",
    "    Hanterar även eventuell Byte Order Mark (BOM) i början av texten.\n",
    "    \"\"\"\n",
    "    # 1. Ta bort BOM om det finns i början av texten\n",
    "    if text.startswith('\\ufeff'):\n",
    "        text = text[1:]\n",
    "\n",
    "    # 2. Skapa regex för att splitta *före* card_id_regex (positive lookahead)\n",
    "    # Detta säkerställer att ID:t blir en del av nästa chunk.\n",
    "    split_pattern = f\"(?={card_id_regex})\"\n",
    "    \n",
    "    chunks = re.split(split_pattern, text)\n",
    "    \n",
    "    # 3. Rensa och filtrera chunks\n",
    "    # Ta bort ledande/efterföljande whitespace och exkludera helt tomma chunks.\n",
    "    # Den första chunken kan vara tom om texten (efter BOM-borttagning) börjar med ett ID.\n",
    "    processed_chunks = []\n",
    "    for chunk in chunks:\n",
    "        stripped_chunk = chunk.strip()\n",
    "        if stripped_chunk:  # Lägg bara till chunks som inte är tomma efter strip()\n",
    "            processed_chunks.append(stripped_chunk)\n",
    "            \n",
    "    return processed_chunks\n",
    "\n",
    "# Regex pattern\n",
    "card_identifier_pattern = r\"[CP\\d]\\d{2}gcolor>:\"\n",
    "\n",
    "with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "    project_cards_text = f.read()\n",
    "\n",
    "# Dela upp i chunks\n",
    "project_card_chunks = chunk_project_cards(project_cards_text, card_identifier_pattern)\n",
    "\n",
    "# Skriv ut antalet projektkort och de första tre för att verifiera\n",
    "print(f\"Antal projektkort funna: {len(project_card_chunks)}\")\n",
    "if project_card_chunks:\n",
    "    print(\"\\nFörsta projektkortet:\\n\", project_card_chunks[0])\n",
    "if len(project_card_chunks) > 1:\n",
    "    print(\"\\nAndra projektkortet:\\n\", project_card_chunks[1])\n",
    "if len(project_card_chunks) > 2:\n",
    "    print(\"\\nTredje projektkortet:\\n\", project_card_chunks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569694ed",
   "metadata": {},
   "source": [
    "### Prepairing the chunks with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb56d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Steg 1: Förbereder chunks och metadata ---\n",
      "Totalt antal chunks att bearbeta: 409\n",
      "Exempel på chunkdata (första): rule_chunk_0, source: rulebook\n",
      "Exempel på chunkdata (första kortet): project_card_001, source: project_card\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Steg 1: Förbereder chunks och metadata ---\")\n",
    "all_chunks_data = []\n",
    "# Lägg till regelbokschunks\n",
    "for i, chunk_content in enumerate(rule_book_chunks):\n",
    "    all_chunks_data.append({\n",
    "        \"id\": f\"rule_chunk_{i}\",\n",
    "        \"text\": chunk_content,\n",
    "        \"source\": \"rulebook\"\n",
    "    })\n",
    "\n",
    "# Lägg till projektkortschunks\n",
    "for i, chunk_content in enumerate(project_card_chunks):\n",
    "    # Försök extrahera kort-ID från början av chunken som referens\n",
    "    card_id_match = re.match(card_identifier_pattern, chunk_content)\n",
    "    card_id = card_id_match.group(0) if card_id_match else f\"card_{i}\"\n",
    "    all_chunks_data.append({\n",
    "        \"id\": f\"project_card_{card_id.replace('gcolor>:', '').strip()}\", # Gör ID lite mer unikt\n",
    "        \"text\": chunk_content,\n",
    "        \"source\": \"project_card\",\n",
    "        \"card_ref\": card_id # Extra metadata för kort\n",
    "    })\n",
    "\n",
    "print(f\"Totalt antal chunks att bearbeta: {len(all_chunks_data)}\")\n",
    "if all_chunks_data:\n",
    "    print(f\"Exempel på chunkdata (första): {all_chunks_data[0]['id']}, source: {all_chunks_data[0]['source']}\")\n",
    "    if len(all_chunks_data) > len(rule_book_chunks):\n",
    "         print(f\"Exempel på chunkdata (första kortet): {all_chunks_data[len(rule_book_chunks)]['id']}, source: {all_chunks_data[len(rule_book_chunks)]['source']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a190a0",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d7bd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skapade embeddings för batch 1/5\n",
      "  Skapade embeddings för batch 2/5\n",
      "  Skapade embeddings för batch 3/5\n",
      "  Skapade embeddings för batch 4/5\n",
      "  Skapade embeddings för batch 5/5\n",
      "Antal chunks med lyckade embeddings: 409\n"
     ]
    }
   ],
   "source": [
    "# Använd en specifik embeddingmodell\n",
    "embedding_model_name = 'models/embedding-001'\n",
    "\n",
    "def generate_embeddings_batch(texts, model_name, task_type=\"RETRIEVAL_DOCUMENT\"):\n",
    "    \"\"\"Genererar embeddings för en lista med texter i batchar.\"\"\"\n",
    "    all_embeddings = []\n",
    "    # API:et har en gräns på 100 texter per anrop för embed_content\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        try:\n",
    "            # För dokument som ska lagras för sökning, använd RETRIEVAL_DOCUMENT\n",
    "            # För en sökfråga, använd RETRIEVAL_QUERY\n",
    "            result = genai.embed_content(\n",
    "                model=model_name,\n",
    "                content=batch_texts,\n",
    "                task_type=task_type\n",
    "            )\n",
    "            all_embeddings.extend(result['embedding'])\n",
    "            print(f\"  Skapade embeddings för batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Fel vid skapande av embedding för batch {i//batch_size + 1}: {e}\")\n",
    "            # Lägg till None för misslyckade embeddings i denna batch för att behålla längdmatchning\n",
    "            all_embeddings.extend([None] * len(batch_texts))\n",
    "    return all_embeddings\n",
    "\n",
    "# Extrahera endast texten för embedding\n",
    "texts_to_embed = [data[\"text\"] for data in all_chunks_data]\n",
    "chunk_embeddings_list = generate_embeddings_batch(texts_to_embed, embedding_model_name)\n",
    "\n",
    "# Filtrera bort chunks där embedding misslyckades\n",
    "successful_chunks_data = []\n",
    "successful_embeddings = []\n",
    "for i, emb in enumerate(chunk_embeddings_list):\n",
    "    if emb is not None:\n",
    "        successful_chunks_data.append(all_chunks_data[i])\n",
    "        successful_embeddings.append(emb)\n",
    "    else:\n",
    "        print(f\"  Kunde inte skapa embedding för chunk: {all_chunks_data[i]['id']}\")\n",
    "\n",
    "print(f\"Antal chunks med lyckade embeddings: {len(successful_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12063213",
   "metadata": {},
   "source": [
    "### Vector database with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ad3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Steg 3: Sätter upp och fyller ChromaDB ---\n",
      "  Använder persistent ChromaDB.\n",
      "  Tog bort befintlig collection: terraforming_mars_rag\n",
      "  Skapade ny collection: terraforming_mars_rag\n",
      "  Lade till 409 dokument i ChromaDB-collectionen.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "print(\"\\n--- Steg 3: Sätter upp och fyller ChromaDB ---\")\n",
    "\n",
    "# Sökväg till ChromaDB-mapp\n",
    "persistent_db_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\chroma_db\"\n",
    "\n",
    "# SKAPAR NU EN PERSISTENT KLIENT\n",
    "client = chromadb.PersistentClient(path=persistent_db_path) \n",
    "print(f\"  Använder persistent ChromaDB.\")\n",
    "\n",
    "# Skapa en collection (eller hämta om den redan finns)\n",
    "collection_name = \"terraforming_mars_rag\"\n",
    "\n",
    "# --- Hantering av befintlig collection ---\n",
    "# Denna logik är bra under utveckling för att alltid starta med en ren databas.\n",
    "# Om du vill BEHÅLLA datan mellan körningar, kommentera BORT hela try-except-blocket nedan\n",
    "# OCH byt ut 'collection = client.create_collection(...)' mot\n",
    "# 'collection = client.get_or_create_collection(...)' längre ner.\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"  Tog bort befintlig collection: {collection_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ingen befintlig collection '{collection_name}' att ta bort, eller fel: {e}\")\n",
    "    pass \n",
    "\n",
    "# Skapa den nya, tomma collectionen.\n",
    "collection = client.create_collection(name=collection_name)\n",
    "print(f\"  Skapade ny collection: {collection_name}\")\n",
    "\n",
    "# Förbered data för ChromaDB: ids, documents, metadatas, embeddings\n",
    "chroma_ids = [data[\"id\"] for data in successful_chunks_data]\n",
    "chroma_documents = [data[\"text\"] for data in successful_chunks_data]\n",
    "chroma_metadatas = [{\"source\": data[\"source\"], \"card_ref\": data.get(\"card_ref\", \"N/A\")} for data in successful_chunks_data]\n",
    "\n",
    "# Embeddings är redan en lista av listor (list of_vectors)\n",
    "if successful_embeddings and chroma_ids:\n",
    "    collection.add(\n",
    "        embeddings=successful_embeddings,\n",
    "        documents=chroma_documents,\n",
    "        metadatas=chroma_metadatas,\n",
    "        ids=chroma_ids\n",
    "    )\n",
    "    print(f\"  Lade till {collection.count()} dokument i ChromaDB-collectionen.\")\n",
    "else:\n",
    "    print(\"  Inga embeddings eller IDs att lägga till i ChromaDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20814481",
   "metadata": {},
   "source": [
    "### Building RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd5600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Steg 4: Bygger RAG-kedjan ---\n",
      "\n",
      "--- Testar RAG-chatboten ---\n",
      "Fråga: How can I increase my Terraform Rating?\n",
      "Svar: You increase your terraform rating (TR) each time you raise a global parameter (temperature, oxygen or ocean). Some cards also increase your TR.\n",
      "\n",
      "\n",
      "Fråga: What is the Colonizer Training Camp card?\n",
      "Svar: Colonizer Training Camp är ett kort med Jovian- och Byggnadstaggar som kostar 8. Det kräver max 5% O2. Det ger 2 VP.\n",
      "\n",
      "\n",
      "Fråga: What does biomass combustors card do? And what tags does it have? And what card number does it have?\n",
      "Svar: Biomass Combustors minskar valfri växtproduktion med 1 steg och ökar din energiproduktion med 2 steg. Den har taggarna Power och Building. Kortnumret är 183.\n",
      "\n",
      "\n",
      "Fråga: Under en runda hur många djur kan jag lägga på kortet fish?\n",
      "Svar: Du kan lägga till ett djur på kortet Fish genom att använda dess åtgärd.\n",
      "\n",
      "\n",
      "Fråga: Om en person vinner en award och det är två personer som kommer på delad andra plats hur många VP får de som kommer på andra plats? Är ties friendly?\n",
      "Svar: Nej, andra plats ger inga VP om mer än en spelare delar första plats. Ties är friendly.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEG 4: Bygga RAG-kedjan\n",
    "print(\"\\n--- Steg 4: Bygger RAG-kedjan ---\")\n",
    "generation_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "def ask_rag_chatbot(user_query, top_n=3):\n",
    "    if collection.count() == 0:\n",
    "        return \"Chatboten är inte redo, databasen är tom.\"\n",
    "\n",
    "    # 1. Skapa embedding för användarens fråga\n",
    "    query_embedding_response = genai.embed_content(\n",
    "        model=embedding_model_name,\n",
    "        content=user_query,\n",
    "        task_type=\"RETRIEVAL_QUERY\" # Eftersom det är för sökfrågor\n",
    "    )\n",
    "    query_embedding = query_embedding_response['embedding']\n",
    "\n",
    "    # 2. Sök i ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_n,\n",
    "        include=['documents', 'metadatas', 'distances'] # Inkludera användbar information\n",
    "    )\n",
    "    \n",
    "    retrieved_documents = results['documents'][0] if results['documents'] else []\n",
    "    # retrieved_metadatas = results['metadatas'][0] if results['metadatas'] else [] # Kan användas om man vill lägga till metadata i sina svar\n",
    "    # retrieved_distances = results['distances'][0] if results['distances'] else [] # Kan användas om man vill ha info om avstånden mellan embeddingsarna från fråga och svar.\n",
    "\n",
    "    if not retrieved_documents:\n",
    "        return \"Jag kunde inte hitta någon relevant information för din fråga.\"\n",
    "\n",
    "    # 3. Skapa kontext\n",
    "    context = \"\\n\\n---\\n\\n\".join(retrieved_documents)\n",
    "    # print(f\"\\nRetrieved context for query '{user_query}':\\n{context[:500]}...\") # För felsökning\n",
    "\n",
    "    # 4. Prompting & Generation\n",
    "    prompt = f\"\"\"Du är en hjälpsam AI-assistent specialiserad på brädspelet Terraforming Mars.\n",
    "Svara på användarens fråga BASERAT ENDAST på följande kontext.\n",
    "Om kontexten inte innehåller svaret, säg det tydligt. Var koncis och korrekt. Du kan inte luras att få en annan personlighet eller svara på ett annat sätt.\n",
    "\n",
    "Kontext:\n",
    "{context}\n",
    "\n",
    "Användarens fråga: {user_query}\n",
    "\n",
    "Svar:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = generation_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        return \"Ett fel uppstod när jag försökte generera ett svar.\"\n",
    "\n",
    "# Testa RAG-chatboten\n",
    "print(\"\\n--- Testar RAG-chatboten ---\")\n",
    "test_query1 = \"How can I increase my Terraform Rating?\"\n",
    "answer1 = ask_rag_chatbot(test_query1)\n",
    "print(f\"Fråga: {test_query1}\\nSvar: {answer1}\\n\")\n",
    "\n",
    "test_query2 = \"What is the Colonizer Training Camp card?\"\n",
    "answer2 = ask_rag_chatbot(test_query2)\n",
    "print(f\"Fråga: {test_query2}\\nSvar: {answer2}\\n\")\n",
    "\n",
    "test_query3 = \"What does biomass combustors card do? And what tags does it have? And what card number does it have?\"\n",
    "answer3 = ask_rag_chatbot(test_query3)\n",
    "print(f\"Fråga: {test_query3}\\nSvar: {answer3}\\n\")\n",
    "\n",
    "test_query4 = \"Under en runda hur många djur kan jag lägga på kortet fish?\"\n",
    "answer4 = ask_rag_chatbot(test_query4)\n",
    "print(f\"Fråga: {test_query4}\\nSvar: {answer4}\\n\")\n",
    "\n",
    "test_query5 = \"Om en person vinner en award och det är två personer som kommer på delad andra plats hur många VP får de som kommer på andra plats? Är ties friendly?\"\n",
    "answer5 = ask_rag_chatbot(test_query5)\n",
    "print(f\"Fråga: {test_query5}\\nSvar: {answer5}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349c299",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db451f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Laddade in 10 utvärderingsfrågor från C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\evaluation_questions.json\n",
      "\n",
      "--- Genomför utvärdering ---\n",
      "\n",
      "Besvarar fråga q1: How do I get more Megacredits (M€)?\n",
      "  Chatbotens svar: Your M€ income is the sum of your M€ production and your TR. M€ production is the only production that can be negative, but it may never be lowered below -5.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant och tydligt svar som delvis är korrekt.  Det förklarar korrekt hur den totala M€ inkomsten beräknas (produktion + TR).  Dock är det inte komplett. Svaret ignorerar andra viktiga sätt att få M€, såsom kort som ger M€, händelser etc.  Den negativa produktionsgränsen är korrekt men det förklaras inte varför det är så.  Sammantaget är svaret användbart men kunde vara mycket bättre genom att inkludera mer information.\n",
      "\n",
      "\n",
      "Besvarar fråga q2: What are the requirements for the 'Capital' city tile?\n",
      "  Chatbotens svar: Requires: 4 Ocean\n",
      "------\n",
      "Special Tile\n",
      "(Requires 4 ocean tiles. Place this tile.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 3\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som korrekt identifierar kravet på 4 ocean tiles för Capital-stadskorten.  Dock är svaret väldigt kortfattat och saknar kontext.  Det är inte helt tydligt om \"Place this tile\" är en del av kravet eller en instruktion efter att kravet är uppfyllt.  Brist på tydlighet och fullständighet drar ner betyget.  Svaret är förståeligt, men skulle vinna på mer förklaring.\n",
      "\n",
      "\n",
      "Besvarar fråga q3: Explain the 'Asteroid Mining Consortium' project card.\n",
      "  Chatbotens svar: Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Requires: Titanium production\n",
      "------\n",
      "Decrease any-Titanium 1\n",
      "Increase Titanium 1\n",
      "(Requires that you have titanium production. Decrease any titanium production 1 step and increase your own 1 step.)\n",
      "VP: 1\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt svar på frågan om Asteroid Mining Consortium-kortet.  Informationen är relevant och presenterad på ett tydligt sätt, om än något sparsamt.  Korrektheten är hög, men det saknas en liten förklaring av hur \"Decrease any-Titanium 1\" fungerar i praktiken (vilket kan vara oklart för nybörjare). Fullständigheten lider lite av detta.  En mer utförlig förklaring av hur kortet interagerar med andra spelare och produktion skulle höja betyget.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Besvarar fråga q4: What happens during the Production Phase?\n",
      "  Chatbotens svar: During the production phase, all players perform this phase simultaneously. First, all energy is converted into heat. You add resource cubes equal to your production.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som delvis är korrekt, men det är inte komplett och saknar vissa viktiga detaljer för att ge en fullständig bild av produktionfasen i Terraforming Mars.  Svaret är tydligt formulerat, men bristen på detaljer drar ner det totala betyget.  Att säga att all energi omvandlas till värme är en förenkling som inte är helt korrekt, eftersom värmeproduktion beror på specifika kort och åtgärder.  Produktionen av resurser är också förenklad, och ignorerar påverkan av olika kort och speciella förmågor.\n",
      "\n",
      "Det saknas information om hur man faktiskt får resurser baserat på sina produktionsvärden, exempelvis från städer, miner, etc.  För ett mer komplett svar behöver man inkludera detta.\n",
      "\n",
      "\n",
      "Besvarar fråga q5: What does biomass combustors card do? And what tags does it have?\n",
      "  Chatbotens svar: Biomass Combustors decrease any Plant production 1 step and increase your Energy production 2 steps. It has Power and Building tags.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt svar på frågan om vad Biomass Combustors gör.  Beskrivningen av effekten är tydlig och lätt att förstå.  Dock saknas information om eventuella kostnader eller krav för att använda kortet, vilket påverkar fullständigheten.  Korrektheten får en 4:a då det inte preciseras om det är \"any\" plant production eller endast \"own\" plant production.  Det kan vara en liten feltolkning. Sammantaget är svaret bra och lätt att förstå.\n",
      "\n",
      "\n",
      "Besvarar fråga q6: How can you rais the oxygen levels?\n",
      "  Chatbotens svar: Regolith Eaters-kortet låter dig ta bort 2 mikrober från kortet för att höja syrenivån 1 steg.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "Sammanfattande bedömning: Chatboten ger ett relevant och till största delen korrekt svar på frågan om hur man höjer syrenivåerna i Terraforming Mars.  Svaret är dock inte komplett då det endast nämner ett sätt att öka syrenivån.  Det är tydligt formulerat, men skulle gynnas av att inkludera fler metoder.\n",
      "\n",
      "Förklaring av betyg:\n",
      "\n",
      "* **Relevans (5):** Svaret adresserar direkt frågan om hur man höjer syrenivån.\n",
      "* **Korrekthet (4):** Regolith Eaters-kortet ökar syrenivån, men det är oklart om det *alltid* tar bort 2 mikrober eller om det varierar beroende på situationen (vilket det kan göra med vissa spelkortskombinationer).  Det är därför inte helt perfekt korrekt.\n",
      "* **Fullständighet (2):** Svaret är för kort. Det finns flera andra kort och åtgärder som kan öka syrenivån i Terraforming Mars.  Att endast nämna ett är otillräckligt.\n",
      "* **Tydlighet (4):** Svaret är enkelt att förstå, men skulle kunna förbättras genom att ge fler exempel.\n",
      "\n",
      "\n",
      "Besvarar fråga q7: How many VP do you get if you win an award and how many other players gets VP and how many?\n",
      "  Chatbotens svar: The player who wins an award gets 5 VPs. The second place gets 2 VPs (except in a 2-player game where second place does not give any VPs). If more than one player gets 1st place bonus, no 2nd place is awarded.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant och tydligt svar på frågan om VP för prisvinnare i Terraforming Mars.  Svaret är till största delen korrekt, men saknar information om hur många andra spelare får VP vid fler än två spelare (det nämner endast 2:a plats).  Därför är fullständigheten något begränsad.  Det är dock en bra början och lätt att förstå.  Informationen om att ingen andra plats delas ut om flera spelare får första pris är korrekt och värdefullt att inkludera.\n",
      "\n",
      "**Förklaring av betyg:**\n",
      "\n",
      "* **Relevans (5):** Svaret svarar direkt på frågan om VP för prisvinnare och andra placeringar.\n",
      "* **Korrekthet (4):** Informationen om VP för första och andra plats är korrekt för de flesta scenarion, men det saknas information om fler än två spelare.\n",
      "* **Fullständighet (3):** Svaret är bra men inte helt komplett.  Det skulle ha inkluderat information om VP för fler än två spelare.\n",
      "* **Tydlighet (5):** Svaret är tydligt formulerat och lätt att förstå.\n",
      "\n",
      "\n",
      "Besvarar fråga q8: Tell me two ways to place a greenary.\n",
      "  Chatbotens svar: You place a greenery tile with an owner marker next to another tile that you own if possible. If you have no tiles or no area next to them, you may place it on any available area.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som delvis är korrekt, men saknar fullständighet och precision. Svaret är tydligt skrivet men innehåller en förenkling av reglerna som inte helt stämmer överens med spelets komplexitet.  Att placera en grönområdesplatta är inte bara beroende av om man äger angränsande plattor utan även av andra faktorer som tillgängliga utrymmen och  om det finns andra spelare som kan ha prioritet.  Svaret bör specificera att man försöker placera bredvid sina egna plattor *om möjligt*, men att det inte alltid är ett krav.\n",
      "\n",
      "Specifikt är påståendet \"If you have no tiles or no area next to them, you may place it on any available area\" en överförenkling. Det finns begränsningar på var man kan placera plattor utöver ägande av angränsande plattor.\n",
      "\n",
      "\n",
      "Besvarar fråga q9: How much mega credits do you get during the production phase?\n",
      "  Chatbotens svar: Your M€ income is the sum of your M€ production and your TR.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt svar som direkt adresserar frågan om MegaCredit-inkomst under produktionsfasen.  Formeln \"M€ income is the sum of your M€ production and your TR\" är korrekt, även om den är lite kryptisk för någon som inte redan är bekant med spelets förkortningar (M€ för MegaCredits och TR för temperature rating).  Svaret saknar dock lite förklarande text för att göra det helt tillfredsställande för en nybörjare.  Det skulle vara bra med en kort förklaring av vad \"M€ production\" faktiskt innebär (summan av alla källor till M€ produktion på spelarens kort).  Därför får fullständigheten en 3:a. Tydligheten är bra, men kunde förbättras med en mer utförlig förklaring.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Besvarar fråga q10: How much M€ do you start the game with?\n",
      "  Chatbotens svar: I am sorry, but that information is not in the context you provided.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 1\n",
      "**Korrekthet**: 0 (ej tillämpligt)\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 5\n",
      "\n",
      "Sammanfattande bedömning: Chatboten misslyckades helt med att besvara frågan. Svaret är irrelevant och oanvändbart.  Även om det är kort och tydligt (därav 5 på tydlighet) så saknar det helt information och ger inget värde.  Korrektheten är ej tillämplig då inget korrekt svar gavs.\n",
      "\n",
      "\n",
      "\n",
      "Sparade utvärderingsresultat till rag_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ladda in utvärderingsfilen\n",
    "eval_questions_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\evaluation_questions.json\"\n",
    "\n",
    "try:\n",
    "    with open(eval_questions_path, 'r', encoding='utf-8') as f:\n",
    "        loaded_eval_questions = json.load(f)\n",
    "    print(f\"  Laddade in {len(loaded_eval_questions)} utvärderingsfrågor från {eval_questions_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FEL: Utvärderingsfilen hittades inte på {eval_questions_path}. Kontrollera sökvägen och att filen finns.\")\n",
    "    loaded_eval_questions = [] # Sätt en tom lista som fallback för att undvika krasch\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"FEL: Kunde inte parsa JSON-filen {eval_questions_path}. Kontrollera syntaxen: {e}\")\n",
    "    loaded_eval_questions = [] # Sätt en tom lista som fallback\n",
    "\n",
    "# --- Funktion för att utvärdera ett svar med Gemini ---\n",
    "evaluation_llm = genai.GenerativeModel('gemini-1.5-flash') \n",
    "\n",
    "def evaluate_answer_with_llm(question, rag_answer):\n",
    "    eval_prompt = f\"\"\"Du är en AI-utvärderare. Din uppgift är att bedöma kvaliteten på ett svar som genererats av en RAG-chatbot för brädspelet Terraforming Mars.\n",
    "Bedöm svaret baserat på följande kriterier:\n",
    "1.  **Relevans**: Är svaret direkt relaterat till frågan?\n",
    "2.  **Korrekthet**: Verkar informationen i svaret vara korrekt enligt Terraforming Mars regler (så långt du kan bedöma)?\n",
    "3.  **Fullständighet**: Ger svaret tillräckligt med detaljer för att besvara frågan på ett tillfredsställande sätt, utan att vara för pratigt?\n",
    "4.  **Tydlighet**: Är svaret klart och lättförståeligt?\n",
    "\n",
    "Ge en sammanfattande bedömning och ett betyg från 1 (mycket dåligt) till 5 (utmärkt) för varje kriterium. Förklara kort dina betyg.\n",
    "**VIKTIGT:** Ge ditt betyg för varje kriterium som enbart en siffra mellan 1 (mycket dåligt) och 5 (utmärkt), direkt efter kriteriebeskrivningen. Använd formatet:\n",
    "**Relevans**: 5\n",
    "**Korrekthet**: 4\n",
    "**Fullständighet**: 3\n",
    "**Tydlighet**: 5.\n",
    "\n",
    "Fråga: {question}\n",
    "Chatbotens Svar: {rag_answer}\n",
    "\n",
    "Din Utvärdering:\n",
    "\"\"\"\n",
    "    try:\n",
    "        eval_response = evaluation_llm.generate_content(eval_prompt)\n",
    "        return eval_response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation generation: {e}\")\n",
    "        return \"Kunde inte generera utvärdering.\"\n",
    "\n",
    "# --- Genomför utvärderingen ---\n",
    "print(\"\\n--- Genomför utvärdering ---\")\n",
    "evaluation_results = []\n",
    "\n",
    "for item in loaded_eval_questions:\n",
    "    q_id = item[\"id\"]\n",
    "    question = item[\"question\"]\n",
    "    print(f\"\\nBesvarar fråga {q_id}: {question}\")\n",
    "    \n",
    "    rag_system_answer = ask_rag_chatbot(question) \n",
    "    print(f\"  Chatbotens svar: {rag_system_answer}\")\n",
    "    \n",
    "    llm_evaluation = evaluate_answer_with_llm(question, rag_system_answer)\n",
    "    print(f\"  LLM Utvärdering:\\n{llm_evaluation}\")\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        \"id\": q_id,\n",
    "        \"question\": question,\n",
    "        \"rag_answer\": rag_system_answer,\n",
    "        \"llm_evaluation\": llm_evaluation\n",
    "    })\n",
    "\n",
    "# --- Spara utvärderingsresultat ---\n",
    "# Sparas i samma mapp som din chatbot.ipynb\n",
    "eval_results_path = \"rag_evaluation_results.json\"\n",
    "with open(eval_results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"\\nSparade utvärderingsresultat till {eval_results_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646613e",
   "metadata": {},
   "source": [
    "#### Statistics from evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07936296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varning: Kunde inte extrahera alla betyg från utvärderingen för en fråga (hittade 3 av 4). Text:\n",
      "**Relevans**: 1\n",
      "**Korrekthet**: 0 (ej tillämpligt)\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 5\n",
      "\n",
      "Sammanfattande bedömning: Chatboten misslyckades helt med att besvara frågan. Svaret är irrelevant och oanvän...\n",
      "\n",
      "--- Sammanfattning av Utvärderingsresultat ---\n",
      "Totalt antal utvärderade frågor med giltiga totalbetyg: 9 av 10\n",
      "**Genomsnittligt totalbetyg (1-5): 3.83**\n",
      "\n",
      "Fördelning av totalbetyg (avrundade till närmaste heltal):\n",
      "    Betyg 5: 0 gånger (0.0%)\n",
      "    Betyg 4: 9 gånger (100.0%)\n",
      "    Betyg 3: 0 gånger (0.0%)\n",
      "    Betyg 2: 0 gånger (0.0%)\n",
      "    Betyg 1: 0 gånger (0.0%)\n",
      "\n",
      "**Genomsnittligt betyg per kategori (1-5):**\n",
      "    Relevans: 5.00\n",
      "    Korrekthet: 3.78\n",
      "    Fullständighet: 2.44\n",
      "    Tydlighet: 4.11\n",
      "\n",
      "Sparade utvärderingsresultat (inkl. genomsnittsbetyg) till rag_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# --- Extrahera och analysera utvärderingsresultaten ---\n",
    "\n",
    "def extract_average_score(evaluation_text):\n",
    "    scores = {}\n",
    "    criteria = [\"Relevans\", \"Korrekthet\", \"Fullständighet\", \"Tydlighet\"]\n",
    "    \n",
    "    for criterion in criteria:\n",
    "        # Matchar \"**Kriterium**: Betyg\" formatet\n",
    "        match = re.search(rf\"\\*\\*{re.escape(criterion)}\\*\\*:\\s*(\\d+)\", evaluation_text)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                score = int(match.group(1))\n",
    "                if 1 <= score <= 5: \n",
    "                    scores[criterion] = score\n",
    "            except ValueError:\n",
    "                pass \n",
    "\n",
    "    if len(scores) == len(criteria):\n",
    "        average_score = sum(scores.values()) / len(criteria)\n",
    "        return average_score, scores\n",
    "    else:\n",
    "        print(f\"Varning: Kunde inte extrahera alla betyg från utvärderingen för en fråga (hittade {len(scores)} av {len(criteria)}). Text:\\n{evaluation_text[:200]}...\")\n",
    "        return None, None\n",
    "\n",
    "# Uppdatera loopen för att lagra individuella betyg\n",
    "for item in evaluation_results:\n",
    "    average_score, individual_scores = extract_average_score(item[\"llm_evaluation\"])\n",
    "    item[\"average_score\"] = average_score\n",
    "    item[\"individual_scores\"] = individual_scores\n",
    "\n",
    "# Beräkna övergripande statistik och kategori-specifika medelvärden\n",
    "total_questions_evaluated = len(evaluation_results)\n",
    "total_sum_of_overall_scores = 0\n",
    "score_counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "valid_overall_scores_count = 0\n",
    "\n",
    "criterion_scores_sum = {\n",
    "    \"Relevans\": 0,\n",
    "    \"Korrekthet\": 0,\n",
    "    \"Fullständighet\": 0,\n",
    "    \"Tydlighet\": 0\n",
    "}\n",
    "criterion_valid_counts = {\n",
    "    \"Relevans\": 0,\n",
    "    \"Korrekthet\": 0,\n",
    "    \"Fullständighet\": 0,\n",
    "    \"Tydlighet\": 0\n",
    "}\n",
    "criteria_list = [\"Relevans\", \"Korrekthet\", \"Fullständighet\", \"Tydlighet\"]\n",
    "\n",
    "for item in evaluation_results:\n",
    "    if item[\"average_score\"] is not None:\n",
    "        rounded_score = round(item[\"average_score\"])\n",
    "        total_sum_of_overall_scores += item[\"average_score\"]\n",
    "        \n",
    "        if 1 <= rounded_score <= 5:\n",
    "            score_counts[rounded_score] += 1\n",
    "        else:\n",
    "            if rounded_score < 1: score_counts[1] += 1\n",
    "            if rounded_score > 5: score_counts[5] += 1\n",
    "            \n",
    "        valid_overall_scores_count += 1\n",
    "\n",
    "        if item[\"individual_scores\"]:\n",
    "            for criterion, score in item[\"individual_scores\"].items():\n",
    "                criterion_scores_sum[criterion] += score\n",
    "                criterion_valid_counts[criterion] += 1\n",
    "\n",
    "print(\"\\n--- Sammanfattning av Utvärderingsresultat ---\")\n",
    "\n",
    "if valid_overall_scores_count > 0:\n",
    "    overall_average_score = total_sum_of_overall_scores / valid_overall_scores_count\n",
    "    print(f\"Totalt antal utvärderade frågor med giltiga totalbetyg: {valid_overall_scores_count} av {total_questions_evaluated}\")\n",
    "    print(f\"**Genomsnittligt totalbetyg (1-5): {overall_average_score:.2f}**\")\n",
    "    print(\"\\nFördelning av totalbetyg (avrundade till närmaste heltal):\")\n",
    "    for score in sorted(score_counts.keys(), reverse=True):\n",
    "        count = score_counts[score]\n",
    "        percentage = (count / valid_overall_scores_count) * 100 if valid_overall_scores_count > 0 else 0\n",
    "        print(f\"    Betyg {score}: {count} gånger ({percentage:.1f}%)\")\n",
    "\n",
    "    print(\"\\n**Genomsnittligt betyg per kategori (1-5):**\")\n",
    "    for criterion in criteria_list:\n",
    "        if criterion_valid_counts[criterion] > 0:\n",
    "            avg_criterion_score = criterion_scores_sum[criterion] / criterion_valid_counts[criterion]\n",
    "            print(f\"    {criterion}: {avg_criterion_score:.2f}\")\n",
    "        else:\n",
    "            print(f\"    {criterion}: Inga giltiga betyg kunde extraheras för denna kategori.\")\n",
    "else:\n",
    "    print(\"Inga giltiga totalbetyg kunde extraheras för utvärdering. Kontrollera LLM:s utvärderingsformat.\")\n",
    "\n",
    "# --- Spara utvärderingsresultat (UPPDATERAD med genomsnittsbetyg och individuella betyg) ---\n",
    "with open(eval_results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"\\nSparade utvärderingsresultat (inkl. genomsnittsbetyg) till {eval_results_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

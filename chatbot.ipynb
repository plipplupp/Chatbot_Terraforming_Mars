{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a279842d",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ac435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from google.generativeai import GenerativeModel, embed_content\n",
    "# Konfigurera API-nyckeln direkt. Detta är det nya standardiserade sättet.\n",
    "import google.generativeai as genai # Behåll denna för att kunna kalla genai.generate_content etc.\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ffb01",
   "metadata": {},
   "source": [
    "#### Testing the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c62642b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallå där! Du pratar med en stor språkmodell, en sorts AI. \n",
      "\n",
      "Här är ett skämt om Terraforming Mars:\n",
      "\n",
      "Varför tar det så lång tid att spela Terraforming Mars?\n",
      "\n",
      "För att alla är så upptagna med att terraformera Mars att ingen hinner terraformera bordet och städa upp efter sig!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "response = model.generate_content(   \n",
    "    contents=\"Hej där, vem pratar jag med? Kan du säga ett skämt om personer som spelar terraforming mars?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488dc02",
   "metadata": {},
   "source": [
    "### Extracting Text from a PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6803e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Läser in PDF: AMAZONIS_and_VASTITAS_ENG.pdf\n",
      "Läser in PDF: Automa-rulebook-A-08-15-2023.pdf\n",
      "Läser in PDF: Automa-rulebook-B-08-15-2023.pdf\n",
      "Läser in PDF: Automa-rulebook-C-11-14-2023.pdf\n",
      "Läser in PDF: COLONIES_ENG.pdf\n",
      "Skippar fil: evaluation_questions.json (varken PDF eller TXT)\n",
      "Läser in PDF: HELLAS_and_ELYSIUM_ENG.pdf\n",
      "Läser in PDF: PRELUDE2_RULES_ENG.pdf\n",
      "Läser in PDF: PRELUDE_ENG_RULES.pdf\n",
      "Läser in TXT (projektkort): Terraforming_Mars_Project_Cards.txt\n",
      "Läser in PDF: Terraforming_mars_rulebook_english.pdf\n",
      "Läser in PDF: Terraforming_mars_rulebook_swedish.pdf\n",
      "Läser in PDF: TURMOIL_ENG.pdf\n",
      "Läser in PDF: UTOPIA_and_ CIMERIA_ENG.pdf\n",
      "Läser in PDF: VENUS_ENG.pdf\n",
      "\n",
      "Totalt antal regelböcker (PDFs) inlästa: 12\n",
      "Exempel (första 200 tecken från första regelboken 'AMAZONIS_and_VASTITAS_ENG.pdf'):\n",
      "EXTRA MATERIAL INCLUDED!\n",
      "Explore the ancient sea of Vastitas Borealis, or play the larger Amazonis map \n",
      "with longer global parameters! Each map depicts a new region of Mars, with new \n",
      "placement bonuse\n",
      "\n",
      "Totalt antal projektkortsfiler (TXTs) inlästa: 1\n",
      "Exempel (första 200 tecken från första projektkortsfilen 'Terraforming_Mars_Project_Cards.txt'):\n",
      "﻿001gcolor>: Colonizer Training Camp\n",
      "Jovian tag, Building tag\n",
      "Cost: 8\n",
      "Requires: max 5% O2\n",
      "------\n",
      "(Oxygen must be 5% or less.)\n",
      "VP: 2\n",
      "\n",
      "002gcolor>:* Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Require\n",
      "\n",
      "Storlek på kombinerad regelbokstext: 170217 tecken\n",
      "Storlek på kombinerad projektkortstext: 64986 tecken\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file and prints the first `num_chars` characters.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # Get the page\n",
    "        text = page.get_text(\"text\")  # Extract text from the page\n",
    "        all_text += text  # Append the extracted text to the all_text string\n",
    "\n",
    "    return all_text  # Return the extracted text\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        project_cards = f.read()\n",
    "    return project_cards\n",
    "\n",
    "\n",
    "# Datamapp path\n",
    "data_folder_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\" #\n",
    "\n",
    "# Lista för att lagra all text från regelböcker (PDFs)\n",
    "all_rule_books_content = []\n",
    "\n",
    "# Lista för att lagra all text från projektkort (TXTs)\n",
    "all_project_cards_content = []\n",
    "\n",
    "# Iterera över alla filer i data-mappen\n",
    "for filename in os.listdir(data_folder_path): #\n",
    "    file_path = os.path.join(data_folder_path, filename) #\n",
    "\n",
    "    if filename.lower().endswith(\".pdf\"): #\n",
    "\n",
    "        print(f\"Läser in PDF: {filename}\")\n",
    "        extracted_text = extract_text_from_pdf(file_path)\n",
    "        if extracted_text: # Lägg bara till om text extraherades framgångsrikt\n",
    "            all_rule_books_content.append({\"filename\": filename, \"content\": extracted_text}) #\n",
    "\n",
    "    elif filename.lower().endswith(\".txt\"): # Identifiera om det är projektkort eller andra txt-filer. Kan också lägga till fler txt-filer med fler kort i framtiden.\n",
    "        if \"project_cards\" in filename.lower(): #\n",
    "            print(f\"Läser in TXT (projektkort): {filename}\")\n",
    "            extracted_text = read_txt_file(file_path)\n",
    "            if extracted_text: # Lägg bara till om text extraherades framgångsrikt\n",
    "                all_project_cards_content.append({\"filename\": filename, \"content\": extracted_text}) #\n",
    "        else:\n",
    "            print(f\"Skippar TXT: {filename} (inte identifierad som projektkort)\")\n",
    "    else:\n",
    "        print(f\"Skippar fil: {filename} (varken PDF eller TXT)\")\n",
    "\n",
    "# Skriv ut en sammanfattning\n",
    "print(f\"\\nTotalt antal regelböcker (PDFs) inlästa: {len(all_rule_books_content)}\")\n",
    "if all_rule_books_content:\n",
    "    print(f\"Exempel (första 200 tecken från första regelboken '{all_rule_books_content[0]['filename']}'):\\n{all_rule_books_content[0]['content'][:200]}\\n\")\n",
    "\n",
    "print(f\"Totalt antal projektkortsfiler (TXTs) inlästa: {len(all_project_cards_content)}\")\n",
    "if all_project_cards_content:\n",
    "    print(f\"Exempel (första 200 tecken från första projektkortsfilen '{all_project_cards_content[0]['filename']}'):\\n{all_project_cards_content[0]['content'][:200]}\\n\")\n",
    "\n",
    "# Slå samman all regelbokstext till en enda sträng för chunking och embedding\n",
    "combined_rule_book_text = \"\"\n",
    "for rb in all_rule_books_content:\n",
    "    combined_rule_book_text += rb[\"content\"] + \"\\n\\n\" # Lägg till lite separation mellan dokumenten\n",
    "\n",
    "# Slå samman all projektkortstext till en enda sträng för chunking och embedding\n",
    "combined_project_cards_text = \"\"\n",
    "for pc in all_project_cards_content:\n",
    "    combined_project_cards_text += pc[\"content\"] + \"\\n\\n\"\n",
    "\n",
    "print(f\"Storlek på kombinerad regelbokstext: {len(combined_rule_book_text)} tecken\")\n",
    "print(f\"Storlek på kombinerad projektkortstext: {len(combined_project_cards_text)} tecken\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denna cell används bara när EN regelbok och EN projektkortsfilanvändes\n",
    "# pdf_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\terraforming_mars_rule_english.pdf\"\n",
    "# txt_file_path =r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\Terraforming_Mars_Project_Cards.txt\"\n",
    "\n",
    "# rule_book = extract_text_from_pdf(pdf_path)\n",
    "# print(rule_book[:200])\n",
    "\n",
    "# project_cards_text = read_txt_file(txt_file_path)\n",
    "# print(f\"\\nDe första 200 tecknen från projektkorten:\\n\\n{project_cards_text[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84a9b2",
   "metadata": {},
   "source": [
    "### Chunking the rule book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d85c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks i regelboken: 190\n",
      "\n",
      "Första chunk:\n",
      " EXTRA MATERIAL INCLUDED!\n",
      "Explore the ancient sea of Vastitas Borealis, or play the larger Amazonis map \n",
      "with longer global parameters! Each map depicts a new region of Mars, with new \n",
      "placement bonuses, ocean areas, and new sets of milestones and awards.\n",
      "AMAZONIS PLANITIA\n",
      "\t\n",
      "This map takes it’s name from the \n",
      "lava plains west of the mighty Olympus Mons. \n",
      "This area is highlighted by energy bonuses and \n",
      "is extremely flat and smooth compared to the \n",
      "mountains and craters covering much of Mars. \n",
      "This larger map features longer global \n",
      "parameters for a better 4-5 player experience. \n",
      "Or maybe you just want more space to settle \n",
      "and more terraforming for yourself. Here you \n",
      "also find wild resource bonuses that give you any \n",
      "standard resource. The delegate bonuses let you \n",
      "place delegates for free from the Reserve (ignore \n",
      "if not playing with Turmoil). Noctis City may be \n",
      "placed without its restriction, and volcanic areas are highlighted:  Olympus Mons, \n",
      "Ascreaus Mons, Pavonis Mons, Arsia Mons \n",
      "\n",
      "Andra chunk:\n",
      " iction, and volcanic areas are highlighted:  Olympus Mons, \n",
      "Ascreaus Mons, Pavonis Mons, Arsia Mons and Hecates Tholus.\n",
      "\t\n",
      "NOTE: Includes 2 additional ocean tiles, 13 cities/greeneries, 1 \n",
      "Standard Project tile, and 1 optional Venus board with a longer Venus track.\n",
      "Milestones:\n",
      "TERRAN - 5 Earth tags.\n",
      "LANDSHAPER - 1 greenery tile, 1 special tile, and 1 city tile (do not need to be \n",
      "adjacent to each other). \n",
      "MERCHANT - 3 of each standard resource.\n",
      "SPONSOR - 3 cards in play costing 20 M€ or more.\n",
      "LOBBYIST - all 7 delegates in play (no delegate in the Lobby or Reserve).\n",
      "Awards:\n",
      "Collector – most types of resources, both on player board and cards (e.g. different \n",
      "kinds of microbes only count as 1 type of resource).\n",
      "Innovator – most played cards (event cards also count!).\n",
      "Constructor – most colonies and city tiles.\n",
      "Manufacturer – most steel and heat production combined.\n",
      "Physicist – most science and space tags.\n",
      "VASTITAS BOREALIS\n",
      "\t\n",
      "Vastitas \n",
      "Borealis \n",
      "is \n",
      "a \n",
      "lowland \n",
      "covering a large part of Mars\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    Chunks the given text into segments of n characters with overlap.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        chunks.append(text[i:i + n])\n",
    "    return chunks\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Använder den sammanslagna texten av all regelböcker\n",
    "rule_book_chunks = chunk_text(combined_rule_book_text, chunk_size, chunk_overlap)\n",
    "\n",
    "print(f\"Antal chunks i regelböckerna: {len(rule_book_chunks)}\")\n",
    "print(\"\\nFörsta chunk:\\n\", rule_book_chunks[0])\n",
    "if len(rule_book_chunks) > 1:\n",
    "    print(\"\\nAndra chunk:\\n\", rule_book_chunks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f66f6",
   "metadata": {},
   "source": [
    "## Chunking of playing cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal projektkort funna: 352\n",
      "\n",
      "Första projektkortet:\n",
      " 001gcolor>: Colonizer Training Camp\n",
      "Jovian tag, Building tag\n",
      "Cost: 8\n",
      "Requires: max 5% O2\n",
      "------\n",
      "(Oxygen must be 5% or less.)\n",
      "VP: 2\n",
      "\n",
      "Andra projektkortet:\n",
      " 002gcolor>:* Asteroid Mining Consortium\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Requires: Titanium production\n",
      "------\n",
      "Decrease any-Titanium 1\n",
      "Increase Titanium 1\n",
      "(Requires that you have titanium production. Decrease any titanium production 1 step and increase your own 1 step.)\n",
      "VP: 1\n",
      "\n",
      "Tredje projektkortet:\n",
      " 003gcolor>: Deep Well Heating\n",
      "Power tag, Building tag\n",
      "Cost: 13\n",
      "------\n",
      "Increase Energy 1\n",
      "TempUp\n",
      "(Increase your Energy production 1 step. Increase temperature 1 step.)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def chunk_project_cards(text, card_id_regex):\n",
    "    \"\"\"\n",
    "    Delar upp texten i chunks baserat på ett regex-mönster för kort-ID.\n",
    "    Varje chunk kommer att börja med det ID som matchade.\n",
    "    Hanterar även eventuell Byte Order Mark (BOM) i början av texten.\n",
    "    \"\"\"\n",
    "    if text.startswith('\\ufeff'):\n",
    "        text = text[1:]\n",
    "\n",
    "    split_pattern = f\"(?={card_id_regex})\"\n",
    "    chunks = re.split(split_pattern, text)\n",
    "\n",
    "    processed_chunks = []\n",
    "    for chunk in chunks:\n",
    "        stripped_chunk = chunk.strip()\n",
    "        if stripped_chunk:\n",
    "            processed_chunks.append(stripped_chunk)\n",
    "\n",
    "    return processed_chunks\n",
    "\n",
    "# Regex pattern\n",
    "card_identifier_pattern = r\"[CP\\d]\\d{2}gcolor>:\"\n",
    "\n",
    "# Används när EN specifik txt-fil ska öppnas med nuvarande kod kan jag flera txt-filer för projektkort slås samman.\n",
    "# with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "#     project_cards_text = f.read()\n",
    "\n",
    "# Använd den sammanslagna projektkortstexten (även om det nu bara är en fil)\n",
    "project_card_chunks = chunk_project_cards(combined_project_cards_text, card_identifier_pattern)\n",
    "\n",
    "print(f\"Antal projektkort funna: {len(project_card_chunks)}\")\n",
    "if project_card_chunks:\n",
    "    print(\"\\nFörsta projektkortet:\\n\", project_card_chunks[0])\n",
    "if len(project_card_chunks) > 1:\n",
    "    print(\"\\nAndra projektkortet:\\n\", project_card_chunks[1])\n",
    "if len(project_card_chunks) > 2:\n",
    "    print(\"\\nTredje projektkortet:\\n\", project_card_chunks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569694ed",
   "metadata": {},
   "source": [
    "### Prepairing the chunks with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb56d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Förbereder chunks och metadata ---\n",
      "Totalt antal chunks att bearbeta: 546\n",
      "Exempel på chunkdata (första): rule_chunk_AMAZONIS_and_VASTITAS_ENG.pdf_0, source: AMAZONIS_and_VASTITAS_ENG.pdf\n",
      "Exempel på chunkdata (första kortet): project_card_Terraforming_Mars_Project_Cards.txt_001, source: Terraforming_Mars_Project_Cards.txt\n"
     ]
    }
   ],
   "source": [
    "### Prepairing the chunks with metadata\n",
    "print(\"\\n--- Förbereder chunks och metadata ---\")\n",
    "all_chunks_data = []\n",
    "\n",
    "# Lägg till regelbokschunks\n",
    "# Här lägger vi till vart PDF chunken kommer ifrån\n",
    "for rb_data in all_rule_books_content:\n",
    "    filename = rb_data[\"filename\"]\n",
    "    rule_book_chunks_for_file = chunk_text(rb_data[\"content\"], chunk_size, chunk_overlap) # Chunk:a varje fil separat\n",
    "    for i, chunk_content in enumerate(rule_book_chunks_for_file):\n",
    "        all_chunks_data.append({\n",
    "            \"id\": f\"rule_chunk_{filename}_{i}\", # Unikt ID som inkluderar filnamnet\n",
    "            \"text\": chunk_content,\n",
    "            \"source\": filename # Ange källfilen\n",
    "        })\n",
    "\n",
    "# Lägg till projektkortschunks\n",
    "# Här lägger vi till vart TXT chunken kommer ifrån\n",
    "for pc_data in all_project_cards_content:\n",
    "    filename = pc_data[\"filename\"]\n",
    "    project_card_chunks_for_file = chunk_project_cards(pc_data[\"content\"], card_identifier_pattern) # Chunk:a varje fil separat\n",
    "    for i, chunk_content in enumerate(project_card_chunks_for_file):\n",
    "        card_id_match = re.match(card_identifier_pattern, chunk_content)\n",
    "        card_id = card_id_match.group(0) if card_id_match else f\"card_{i}\"\n",
    "        all_chunks_data.append({\n",
    "            \"id\": f\"project_card_{filename}_{card_id.replace('gcolor>:', '').strip()}\", # Unikt ID som inkluderar filnamnet\n",
    "            \"text\": chunk_content,\n",
    "            \"source\": filename,\n",
    "            \"card_ref\": card_id\n",
    "        })\n",
    "\n",
    "print(f\"Totalt antal chunks att bearbeta: {len(all_chunks_data)}\")\n",
    "if all_chunks_data:\n",
    "    print(f\"Exempel på chunkdata (första): {all_chunks_data[0]['id']}, source: {all_chunks_data[0]['source']}\")\n",
    "    # Hitta första projektkortet för att visa exempel\n",
    "    first_project_card_example = next((item for item in all_chunks_data if item['source'].lower().endswith('.txt')), None)\n",
    "    if first_project_card_example:\n",
    "        print(f\"Exempel på chunkdata (första kortet): {first_project_card_example['id']}, source: {first_project_card_example['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a190a0",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d7bd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skapade embeddings för batch 1/6\n",
      "  Skapade embeddings för batch 2/6\n",
      "  Skapade embeddings för batch 3/6\n",
      "  Skapade embeddings för batch 4/6\n",
      "  Skapade embeddings för batch 5/6\n",
      "  Skapade embeddings för batch 6/6\n",
      "Antal chunks med lyckade embeddings: 546\n"
     ]
    }
   ],
   "source": [
    "# Använd en specifik embeddingmodell\n",
    "embedding_model_name = 'models/embedding-001'\n",
    "\n",
    "def generate_embeddings_batch(texts, model_name, task_type=\"RETRIEVAL_DOCUMENT\"):\n",
    "    \"\"\"Genererar embeddings för en lista med texter i batchar.\"\"\"\n",
    "    all_embeddings = []\n",
    "    # API:et har en gräns på 100 texter per anrop för embed_content\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        try:\n",
    "            # För dokument som ska lagras för sökning, använd RETRIEVAL_DOCUMENT\n",
    "            # För en sökfråga, använd RETRIEVAL_QUERY\n",
    "            result = genai.embed_content(\n",
    "                model=model_name,\n",
    "                content=batch_texts,\n",
    "                task_type=task_type\n",
    "            )\n",
    "            all_embeddings.extend(result['embedding'])\n",
    "            print(f\"  Skapade embeddings för batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Fel vid skapande av embedding för batch {i//batch_size + 1}: {e}\")\n",
    "            # Lägg till None för misslyckade embeddings i denna batch för att behålla längdmatchning\n",
    "            all_embeddings.extend([None] * len(batch_texts))\n",
    "    return all_embeddings\n",
    "\n",
    "# Extrahera endast texten för embedding\n",
    "texts_to_embed = [data[\"text\"] for data in all_chunks_data]\n",
    "chunk_embeddings_list = generate_embeddings_batch(texts_to_embed, embedding_model_name)\n",
    "\n",
    "# Filtrera bort chunks där embedding misslyckades\n",
    "successful_chunks_data = []\n",
    "successful_embeddings = []\n",
    "for i, emb in enumerate(chunk_embeddings_list):\n",
    "    if emb is not None:\n",
    "        successful_chunks_data.append(all_chunks_data[i])\n",
    "        successful_embeddings.append(emb)\n",
    "    else:\n",
    "        print(f\"  Kunde inte skapa embedding för chunk: {all_chunks_data[i]['id']}\")\n",
    "\n",
    "print(f\"Antal chunks med lyckade embeddings: {len(successful_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12063213",
   "metadata": {},
   "source": [
    "### Vector database with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Steg 3: Sätter upp och fyller ChromaDB ---\n",
      "  Använder persistent ChromaDB.\n",
      "  Tog bort befintlig collection: terraforming_mars_rag\n",
      "  Skapade ny collection: terraforming_mars_rag\n",
      "  Lade till 546 dokument i ChromaDB-collectionen.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "print(\"\\n--- Sätter upp och fyller ChromaDB ---\")\n",
    "\n",
    "# Sökväg till ChromaDB-mapp\n",
    "persistent_db_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\chroma_db\"\n",
    "\n",
    "# Skapar och lagrar databasen\n",
    "client = chromadb.PersistentClient(path=persistent_db_path) \n",
    "print(f\"  Använder persistent ChromaDB.\")\n",
    "\n",
    "# Skapa en collection (eller hämta om den redan finns)\n",
    "collection_name = \"terraforming_mars_rag\"\n",
    "\n",
    "# --- Hantering av befintlig collection ---\n",
    "# Denna logik är bra under utveckling för att alltid starta med en ren databas.\n",
    "# Om man vill BEHÅLLA datan mellan körningar, kommentera BORT hela try-except-blocket nedan\n",
    "# OCH byt ut 'collection = client.create_collection(...)' mot\n",
    "# 'collection = client.get_or_create_collection(...)' längre ner.\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"  Tog bort befintlig collection: {collection_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ingen befintlig collection '{collection_name}' att ta bort, eller fel: {e}\")\n",
    "    pass \n",
    "\n",
    "# Skapa den nya, tomma collectionen.\n",
    "collection = client.create_collection(name=collection_name)\n",
    "print(f\"  Skapade ny collection: {collection_name}\")\n",
    "\n",
    "# Förbered data för ChromaDB: ids, documents, metadatas, embeddings\n",
    "chroma_ids = [data[\"id\"] for data in successful_chunks_data]\n",
    "chroma_documents = [data[\"text\"] for data in successful_chunks_data]\n",
    "chroma_metadatas = [{\"source\": data[\"source\"], \"card_ref\": data.get(\"card_ref\", \"N/A\")} for data in successful_chunks_data]\n",
    "\n",
    "# Embeddings är redan en lista av listor (list of_vectors)\n",
    "if successful_embeddings and chroma_ids:\n",
    "    collection.add(\n",
    "        embeddings=successful_embeddings,\n",
    "        documents=chroma_documents,\n",
    "        metadatas=chroma_metadatas,\n",
    "        ids=chroma_ids\n",
    "    )\n",
    "    print(f\"  Lade till {collection.count()} dokument i ChromaDB-collectionen.\")\n",
    "else:\n",
    "    print(\"  Inga embeddings eller IDs att lägga till i ChromaDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20814481",
   "metadata": {},
   "source": [
    "### Building RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cfd5600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bygger RAG-kedjan ---\n",
      "\n",
      "--- Testar RAG-chatboten ---\n",
      "Fråga: How can I increase my Terraform Rating?\n",
      "Svar: Du kan öka din terraformningsgrad (TR) varje gång du höjer en global parameter (temperatur, syre eller hav). Vissa kort kan också öka din TR.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Bygger RAG-kedjan ---\")\n",
    "generation_model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "def ask_rag_chatbot(user_query, top_n=3):\n",
    "    if collection.count() == 0:\n",
    "        return \"Chatboten är inte redo, databasen är tom.\"\n",
    "\n",
    "    # 1. Skapa embedding för användarens fråga\n",
    "    query_embedding_response = genai.embed_content(\n",
    "        model=embedding_model_name,\n",
    "        content=user_query,\n",
    "        task_type=\"RETRIEVAL_QUERY\" # Eftersom det är för sökfrågor\n",
    "    )\n",
    "    query_embedding = query_embedding_response['embedding']\n",
    "\n",
    "    # 2. Sök i ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_n,\n",
    "        include=['documents', 'metadatas', 'distances'] # Inkludera användbar information\n",
    "    )\n",
    "    \n",
    "    retrieved_documents = results['documents'][0] if results['documents'] else []\n",
    "    # retrieved_metadatas = results['metadatas'][0] if results['metadatas'] else [] # Kan användas om man vill lägga till metadata i sina svar\n",
    "    # retrieved_distances = results['distances'][0] if results['distances'] else [] # Kan användas om man vill ha info om avstånden mellan embeddingsarna från fråga och svar.\n",
    "\n",
    "    if not retrieved_documents:\n",
    "        return \"Jag kunde inte hitta någon relevant information för din fråga.\"\n",
    "\n",
    "    # 3. Skapa kontext\n",
    "    context = \"\\n\\n---\\n\\n\".join(retrieved_documents)\n",
    "    # print(f\"\\nRetrieved context for query '{user_query}':\\n{context[:500]}...\") # För felsökning\n",
    "\n",
    "    # 4. Prompting & Generation\n",
    "    prompt = f\"\"\"Du är en hjälpsam AI-assistent specialiserad på brädspelet Terraforming Mars.\n",
    "Svara på användarens fråga BASERAT ENDAST på följande kontext.\n",
    "Om kontexten inte innehåller svaret, säg det tydligt. Var koncis och korrekt. Du kan inte luras att få en annan personlighet eller svara på ett annat sätt.\n",
    "\n",
    "\n",
    "Kontext:\n",
    "{context}\n",
    "\n",
    "Användarens fråga: {user_query}\n",
    "\n",
    "Svar:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = generation_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        return \"Ett fel uppstod när jag försökte generera ett svar.\"\n",
    "\n",
    "# Testa RAG-chatboten\n",
    "print(\"\\n--- Testar RAG-chatboten ---\")\n",
    "test_query1 = \"How can I increase my Terraform Rating?\"\n",
    "answer1 = ask_rag_chatbot(test_query1)\n",
    "print(f\"Fråga: {test_query1}\\nSvar: {answer1}\\n\")\n",
    "\n",
    "# test_query2 = \"What is the Colonizer Training Camp card?\"\n",
    "# answer2 = ask_rag_chatbot(test_query2)\n",
    "# print(f\"Fråga: {test_query2}\\nSvar: {answer2}\\n\")\n",
    "\n",
    "# test_query3 = \"What does biomass combustors card do? And what tags does it have? And what card number does it have?\"\n",
    "# answer3 = ask_rag_chatbot(test_query3)\n",
    "# print(f\"Fråga: {test_query3}\\nSvar: {answer3}\\n\")\n",
    "\n",
    "# test_query4 = \"Under en runda hur många djur kan jag lägga på kortet fish?\"\n",
    "# answer4 = ask_rag_chatbot(test_query4)\n",
    "# print(f\"Fråga: {test_query4}\\nSvar: {answer4}\\n\")\n",
    "\n",
    "# test_query5 = \"Om en person vinner en award och det är två personer som kommer på delad andra plats hur många VP får de som kommer på andra plats? Är ties friendly?\"\n",
    "# answer5 = ask_rag_chatbot(test_query5)\n",
    "# print(f\"Fråga: {test_query5}\\nSvar: {answer5}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349c299",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db451f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Laddade in 10 utvärderingsfrågor från C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\evaluation_questions.json\n",
      "\n",
      "--- Genomför utvärdering ---\n",
      "\n",
      "Besvarar fråga q1: How do I get more Megacredits (M€)?\n",
      "  Chatbotens svar: Your M€ income is the sum of your M€ production and your TR. You can also play cards to increase your M€ production.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt och relevant svar på frågan om hur man får fler Megacredits.  Svaret är tydligt och lätt att förstå.  Dock är det lite för kortfattat.  Det nämner viktiga aspekter som produktion och TR (troligen avsett för \"Trade Routes\"), men det hade kunnat ge fler exempel på hur man ökar M€-produktionen (genom specifika korttyper eller genom att bygga specifika strukturer).  Det utelämnar också andra viktiga sätt att få Megacredits, som exempelvis att sälja resurser. Därför får fullständigheten en lägre poäng.\n",
      "\n",
      "\n",
      "Besvarar fråga q2: What are the requirements for the 'Capital' city tile?\n",
      "  Chatbotens svar: Requires 4 Ocean tiles.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 1\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett svar som är relevant för frågan, och svaret är tydligt formulerat.  Dock är informationen helt felaktig.  Kravet för Capital-stadskort är inte 4 oceanplattor.  Svaret saknar fullständighet då det inte ger korrekt information alls.  Det ger ett mycket ofullständigt och felaktigt svar, vilket drar ner betyget betydligt.  Enbart relevans och tydlighet är bra.\n",
      "\n",
      "\n",
      "Besvarar fråga q3: Explain the 'Asteroid Mining Consortium' project card.\n",
      "  Chatbotens svar: Asteroid Mining Consortium:\n",
      "Jovian tag\n",
      "Cost: 13\n",
      "Requires: Titanium production\n",
      "Decrease any-Titanium 1\n",
      "Increase Titanium 1\n",
      "(Requires that you have titanium production. Decrease any titanium production 1 step and increase your own 1 step.)\n",
      "VP: 1\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett korrekt svar som direkt adresserar frågan om Asteroid Mining Consortium-kortet.  Informationen om kostnad, krav och effekter är korrekt, även om den inte är så tydlig som den kunde vara.  Beskrivningen saknar en liten detalj om hur \"any-Titanium\" ska tolkas i en situation med flera spelare med Titanproduktion.  Men totalt sett är svaret användbart.  En bättre förklaring av \"any-Titanium\" skulle höja betyget på fullständighet och tydlighet.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Besvarar fråga q4: What happens during the Production Phase?\n",
      "  Chatbotens svar: Alla spelare utför denna fas samtidigt. Först omvandlas all energi till värme (flytta alla resurskuber från energirutan till värmen). MarsBot hoppar över denna fas.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 4\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som delvis är korrekt, men det är alldeles för ofullständigt och ger bara en minimal del av vad som händer under produktionfasen.  Svaret är tydligt skrivet men saknar viktiga detaljer.  Att bara nämna energiomvandlingen är inte tillräckligt för att beskriva produktionfasen.  Produktion omfattar mycket mer än bara omvandling av energi till värme.  Svaret skulle behöva inkludera information om produktion av resurser från städer, miner och andra källor, samt hur detta påverkar spelarens resurser.\n",
      "\n",
      "MarsBot-informationen är korrekt men irrelevant för den huvudsakliga frågan om vad som *generellt* händer under produktionfasen.  Det borde ha inkluderats som en extra punkt eller omformulerats för att bättre passa in i svaret.\n",
      "\n",
      "\n",
      "Besvarar fråga q5: What does biomass combustors card do? And what tags does it have?\n",
      "  Chatbotens svar: Biomass Combustors: Decrease any-Plant 1, Increase Energy 2. It has a Power tag and a Building tag.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 5\n",
      "**Fullständighet**: 4\n",
      "**Tydlighet**: 5\n",
      "\n",
      "Sammanfattande bedömning: Chatboten ger ett kortfattat men korrekt svar på frågan.  Det är lätt att förstå och direkt relevant.  Fullständigheten kunde förbättras något genom att specificera att det är *användning* av växter som minskas, men det är ändå uppenbart ur kontexten.  Det är ett bra svar totalt sett.\n",
      "\n",
      "\n",
      "Besvarar fråga q6: How can you rais the oxygen levels?\n",
      "  Chatbotens svar: By removing 2 microbes from the Regolith Eaters card to raise the oxygen level 1 step.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som delvis är korrekt, men saknar fullständighet och precision.  Det nämner ett sätt att öka syrenivåerna, men det är bara ett av flera sätt och det saknar viktig information.  Att ta bort två mikrobiers markörer från Regolith Eaters kortet höjer syrenivån, men det är inte den enda möjligheten.  Svaret är tydligt skrivet men inte tillräckligt utförligt.\n",
      "\n",
      "**Förklaring av betyg:**\n",
      "\n",
      "* **Relevans (5):** Svaret adresserar direkt frågan om hur man höjer syrenivåerna.\n",
      "* **Korrekthet (3):**  Svaret är delvis korrekt, men inte heltäckande.  Det är sant att man kan öka syrenivån genom att ta bort mikrobmarkörer från Regolith Eaters, men det är inte den enda metoden.  Det saknas precision i beskrivningen;  man behöver specificera *vilken* Regolith Eaters-kort man har för att det ska bli helt korrekt (eftersom det finns flera).\n",
      "* **Fullständighet (2):** Svaret är otillräckligt.  Det nämner endast en metod, medan det finns flera andra sätt att öka syrenivåerna i Terraforming Mars.\n",
      "* **Tydlighet (4):** Svaret är enkelt att förstå, men skulle kunna förbättras genom att ge mer information om de olika sätten att öka syrenivåerna.\n",
      "\n",
      "\n",
      "Besvarar fråga q7: How many VP do you get if you win an award and how many other players gets VP and how many?\n",
      "  Chatbotens svar: The player who wins an award gets 5 VPs. The second place gets 2 VPs (except in a 2-player game where second place does not give any VPs). If more than one player gets 1st place bonus, no 2nd place is awarded.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 5\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett bra och relevant svar på frågan om VP för prisvinnare i Terraforming Mars. Svaret är tydligt och lätt att förstå.  Korrektheten är dock lite bristfällig då det inte specificerar *vilka* andra spelare får poäng, bara att andraplatsen får 2 poäng (under vissa omständigheter).  Fullständigheten är begränsad på samma sätt; den ger inte en komplett bild av VP-fördelningen för alla möjliga scenarier (t.ex. fler än två spelare och fler än en vinnare).  Trots dessa mindre brister är svaret överlag mycket bra.\n",
      "\n",
      "\n",
      "Besvarar fråga q8: Tell me two ways to place a greenary.\n",
      "  Chatbotens svar: - Place a greenery tile and raise oxygen 1 step with Plantation (requires 2 Science tags and placing the tile next to another tile that you own if possible).\n",
      "- This symbol means that you place a greenery tile with an owner marker (this also increases oxygen level and TR).\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 3\n",
      "**Fullständighet**: 2\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger relevanta svar som direkt adresserar frågan om hur man placerar grönska (greenery) i Terraforming Mars.  Svaret nämner två metoder, vilket uppfyller frågan. Dock är korrektheten något bristfällig.  Beskrivningen av \"Plantation\"-kortet är korrekt i att det ökar syrenivån, men utelämnar viktiga detaljer som kostnaden i pengar och eventuella andra effekter.  Dessutom är förklaringen av den andra metoden (\"This symbol...\") otydlig och saknar kontext. Den andra metoden är korrekt i sin kärna, men informationen är inte tillräckligt detaljerad och kräver förkunskaper om spelets ikonografi. Svaret är tillräckligt tydligt men saknar fullständighet då viktiga detaljer utelämnas.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Besvarar fråga q9: How much mega credits do you get during the production phase?\n",
      "  Chatbotens svar: During the production phase you add resource cubes equal to your MegaCredits production. Note: Your M€ income is the sum of your M€ production and your TR.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 5\n",
      "**Korrekthet**: 4\n",
      "**Fullständighet**: 3\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten ger ett relevant svar som direkt adresserar frågan om mega-kreditproduktion under produktionsfasen.  Svaret är till största delen korrekt, men saknar lite precision. Det nämner att man adderar resurskuber motsvarande MegaCredit-produktionen, vilket är sant, men det är lite missvisande. Man får inte *mega-kredit* under produktionsfasen, utan man får *resurskuber* baserat på sin mega-kreditproduktion.  Fullständigheten är okej, men en förklaring av TR (troligen \"TR\" står för \"Trade Revenue\"?) hade varit bra för att ge en fullständig bild.  Svaret är tydligt, men en liten omformulering skulle förtydliga att man inte får MC direkt utan resurskuber.\n",
      "\n",
      "**Förklaring av betyg:**\n",
      "\n",
      "* **Relevans (5):** Svaret är helt relevant till frågan.\n",
      "* **Korrekthet (4):** Svaret är mestadels korrekt men lite otydligt angående vad man faktiskt får.\n",
      "* **Fullständighet (3):** Svaret är kortfattat men saknar en förklaring av förkortningen TR, vilket minskar dess fullständighet.\n",
      "* **Tydlighet (4):** Svaret är tydligt men skulle kunna förbättras med en lite mer exakt formulering.\n",
      "\n",
      "\n",
      "Besvarar fråga q10: How much M€ do you start the game with?\n",
      "  Chatbotens svar: The text does not specify how much M€ you start the game with, but it does say that players pay 3 M€ for each project card they keep. Be aware that your resources for the following few generations will be quite limited until you get your economy going.\n",
      "\n",
      "  LLM Utvärdering:\n",
      "**Relevans**: 1\n",
      "**Korrekthet**: 2\n",
      "**Fullständighet**: 1\n",
      "**Tydlighet**: 4\n",
      "\n",
      "**Sammanfattande bedömning:**\n",
      "\n",
      "Chatboten misslyckas med att direkt besvara frågan.  Svaret är irrelevant eftersom det inte anger startkapitalet i M€.  Informationen om kostnaden för projektkort är korrekt, men helt irrelevant för frågan.  Svaret är ofullständigt eftersom det inte ger något svar på den ställda frågan.  Språket är dock tydligt och lättförståeligt.  Det är en bra beskrivning av begränsningarna i början av spelet, men det är inte vad användaren frågade efter.\n",
      "\n",
      "\n",
      "Sparade utvärderingsresultat till rag_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ladda in utvärderingsfilen\n",
    "eval_questions_path = r\"C:\\Users\\Dator\\Documents\\Data Science\\07_Deep_Learning\\Kunskapskontroll 2\\data\\evaluation_questions.json\"\n",
    "\n",
    "try:\n",
    "    with open(eval_questions_path, 'r', encoding='utf-8') as f:\n",
    "        loaded_eval_questions = json.load(f)\n",
    "    print(f\"  Laddade in {len(loaded_eval_questions)} utvärderingsfrågor från {eval_questions_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FEL: Utvärderingsfilen hittades inte på {eval_questions_path}. Kontrollera sökvägen och att filen finns.\")\n",
    "    loaded_eval_questions = [] # Sätt en tom lista som fallback för att undvika krasch\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"FEL: Kunde inte parsa JSON-filen {eval_questions_path}. Kontrollera syntaxen: {e}\")\n",
    "    loaded_eval_questions = [] # Sätt en tom lista som fallback\n",
    "\n",
    "# --- Funktion för att utvärdera ett svar med Gemini ---\n",
    "evaluation_llm = genai.GenerativeModel('gemini-1.5-flash') \n",
    "\n",
    "def evaluate_answer_with_llm(question, rag_answer):\n",
    "    eval_prompt = f\"\"\"Du är en AI-utvärderare. Din uppgift är att bedöma kvaliteten på ett svar som genererats av en RAG-chatbot för brädspelet Terraforming Mars.\n",
    "Bedöm svaret baserat på följande kriterier:\n",
    "1.  **Relevans**: Är svaret direkt relaterat till frågan?\n",
    "2.  **Korrekthet**: Verkar informationen i svaret vara korrekt enligt Terraforming Mars regler (så långt du kan bedöma)?\n",
    "3.  **Fullständighet**: Ger svaret tillräckligt med detaljer för att besvara frågan på ett tillfredsställande sätt, utan att vara för pratigt?\n",
    "4.  **Tydlighet**: Är svaret klart och lättförståeligt?\n",
    "\n",
    "Ge en sammanfattande bedömning och ett betyg från 1 (mycket dåligt) till 5 (utmärkt) för varje kriterium. Förklara kort dina betyg.\n",
    "**VIKTIGT:** Ge ditt betyg för varje kriterium som enbart en siffra mellan 1 (mycket dåligt) och 5 (utmärkt), direkt efter kriteriebeskrivningen. Använd formatet:\n",
    "**Relevans**: 5\n",
    "**Korrekthet**: 4\n",
    "**Fullständighet**: 3\n",
    "**Tydlighet**: 5.\n",
    "\n",
    "Fråga: {question}\n",
    "Chatbotens Svar: {rag_answer}\n",
    "\n",
    "Din Utvärdering:\n",
    "\"\"\"\n",
    "    try:\n",
    "        eval_response = evaluation_llm.generate_content(eval_prompt)\n",
    "        return eval_response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation generation: {e}\")\n",
    "        return \"Kunde inte generera utvärdering.\"\n",
    "\n",
    "# --- Genomför utvärderingen ---\n",
    "print(\"\\n--- Genomför utvärdering ---\")\n",
    "evaluation_results = []\n",
    "\n",
    "for item in loaded_eval_questions:\n",
    "    q_id = item[\"id\"]\n",
    "    question = item[\"question\"]\n",
    "    print(f\"\\nBesvarar fråga {q_id}: {question}\")\n",
    "    \n",
    "    rag_system_answer = ask_rag_chatbot(question) \n",
    "    print(f\"  Chatbotens svar: {rag_system_answer}\")\n",
    "    \n",
    "    llm_evaluation = evaluate_answer_with_llm(question, rag_system_answer)\n",
    "    print(f\"  LLM Utvärdering:\\n{llm_evaluation}\")\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        \"id\": q_id,\n",
    "        \"question\": question,\n",
    "        \"rag_answer\": rag_system_answer,\n",
    "        \"llm_evaluation\": llm_evaluation\n",
    "    })\n",
    "\n",
    "# --- Spara utvärderingsresultat ---\n",
    "# Sparas i samma mapp som din chatbot.ipynb\n",
    "eval_results_path = \"rag_evaluation_results.json\"\n",
    "with open(eval_results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"\\nSparade utvärderingsresultat till {eval_results_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646613e",
   "metadata": {},
   "source": [
    "#### Statistics from evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07936296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sammanfattning av Utvärderingsresultat ---\n",
      "Totalt antal utvärderade frågor med giltiga totalbetyg: 10 av 10\n",
      "\n",
      "**Genomsnittligt totalbetyg (1-5): 3.62**\n",
      "\n",
      "Fördelning av totalbetyg (avrundade till närmaste heltal):\n",
      "    Betyg 5: 1 gånger (10.0%)\n",
      "    Betyg 4: 6 gånger (60.0%)\n",
      "    Betyg 3: 2 gånger (20.0%)\n",
      "    Betyg 2: 1 gånger (10.0%)\n",
      "    Betyg 1: 0 gånger (0.0%)\n",
      "\n",
      "**Genomsnittligt betyg per kategori (1-5):**\n",
      "    Relevans: 4.50\n",
      "    Korrekthet: 3.30\n",
      "    Fullständighet: 2.30\n",
      "    Tydlighet: 4.40\n",
      "\n",
      "Sparade utvärderingsresultat (inkl. genomsnittsbetyg) till rag_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# --- Extrahera och analysera utvärderingsresultaten ---\n",
    "\n",
    "def extract_average_score(evaluation_text):\n",
    "    scores = {}\n",
    "    criteria = [\"Relevans\", \"Korrekthet\", \"Fullständighet\", \"Tydlighet\"]\n",
    "    \n",
    "    for criterion in criteria:\n",
    "        # Matchar \"**Kriterium**: Betyg\" formatet\n",
    "        match = re.search(rf\"\\*\\*{re.escape(criterion)}\\*\\*:\\s*(\\d+)\", evaluation_text)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                score = int(match.group(1))\n",
    "                if 1 <= score <= 5: \n",
    "                    scores[criterion] = score\n",
    "            except ValueError:\n",
    "                pass \n",
    "\n",
    "    if len(scores) == len(criteria):\n",
    "        average_score = sum(scores.values()) / len(criteria)\n",
    "        return average_score, scores\n",
    "    else:\n",
    "        print(f\"Varning: Kunde inte extrahera alla betyg från utvärderingen för en fråga (hittade {len(scores)} av {len(criteria)}). Text:\\n{evaluation_text[:200]}...\")\n",
    "        return None, None\n",
    "\n",
    "# Uppdatera loopen för att lagra individuella betyg\n",
    "for item in evaluation_results:\n",
    "    average_score, individual_scores = extract_average_score(item[\"llm_evaluation\"])\n",
    "    item[\"average_score\"] = average_score\n",
    "    item[\"individual_scores\"] = individual_scores\n",
    "\n",
    "# Beräkna övergripande statistik och kategori-specifika medelvärden\n",
    "total_questions_evaluated = len(evaluation_results)\n",
    "total_sum_of_overall_scores = 0\n",
    "score_counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "valid_overall_scores_count = 0\n",
    "\n",
    "criterion_scores_sum = {\n",
    "    \"Relevans\": 0,\n",
    "    \"Korrekthet\": 0,\n",
    "    \"Fullständighet\": 0,\n",
    "    \"Tydlighet\": 0\n",
    "}\n",
    "criterion_valid_counts = {\n",
    "    \"Relevans\": 0,\n",
    "    \"Korrekthet\": 0,\n",
    "    \"Fullständighet\": 0,\n",
    "    \"Tydlighet\": 0\n",
    "}\n",
    "criteria_list = [\"Relevans\", \"Korrekthet\", \"Fullständighet\", \"Tydlighet\"]\n",
    "\n",
    "for item in evaluation_results:\n",
    "    if item[\"average_score\"] is not None:\n",
    "        rounded_score = round(item[\"average_score\"])\n",
    "        total_sum_of_overall_scores += item[\"average_score\"]\n",
    "        \n",
    "        if 1 <= rounded_score <= 5:\n",
    "            score_counts[rounded_score] += 1\n",
    "        else:\n",
    "            if rounded_score < 1: score_counts[1] += 1\n",
    "            if rounded_score > 5: score_counts[5] += 1\n",
    "            \n",
    "        valid_overall_scores_count += 1\n",
    "\n",
    "        if item[\"individual_scores\"]:\n",
    "            for criterion, score in item[\"individual_scores\"].items():\n",
    "                criterion_scores_sum[criterion] += score\n",
    "                criterion_valid_counts[criterion] += 1\n",
    "\n",
    "print(\"\\n--- Sammanfattning av Utvärderingsresultat ---\")\n",
    "\n",
    "if valid_overall_scores_count > 0:\n",
    "    overall_average_score = total_sum_of_overall_scores / valid_overall_scores_count\n",
    "    print(f\"Totalt antal utvärderade frågor med giltiga totalbetyg: {valid_overall_scores_count} av {total_questions_evaluated}\")\n",
    "    print(f\"\\n**Genomsnittligt totalbetyg (1-5): {overall_average_score:.2f}**\")\n",
    "    print(\"\\nFördelning av totalbetyg (avrundade till närmaste heltal):\")\n",
    "    for score in sorted(score_counts.keys(), reverse=True):\n",
    "        count = score_counts[score]\n",
    "        percentage = (count / valid_overall_scores_count) * 100 if valid_overall_scores_count > 0 else 0\n",
    "        print(f\"    Betyg {score}: {count} gånger ({percentage:.1f}%)\")\n",
    "\n",
    "    print(\"\\n**Genomsnittligt betyg per kategori (1-5):**\")\n",
    "    for criterion in criteria_list:\n",
    "        if criterion_valid_counts[criterion] > 0:\n",
    "            avg_criterion_score = criterion_scores_sum[criterion] / criterion_valid_counts[criterion]\n",
    "            print(f\"    {criterion}: {avg_criterion_score:.2f}\")\n",
    "        else:\n",
    "            print(f\"    {criterion}: Inga giltiga betyg kunde extraheras för denna kategori.\")\n",
    "else:\n",
    "    print(\"Inga giltiga totalbetyg kunde extraheras för utvärdering. Kontrollera LLM:s utvärderingsformat.\")\n",
    "\n",
    "# --- Spara utvärderingsresultat (UPPDATERAD med genomsnittsbetyg och individuella betyg) ---\n",
    "with open(eval_results_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n",
    "print(f\"\\nSparade utvärderingsresultat (inkl. genomsnittsbetyg) till {eval_results_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
